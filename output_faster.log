nohup: ignoring input
Using cuda device
Training:   0%|          | 0/471 [00:00<?, ?it/s]Training:   0%|          | 1/471 [00:11<1:29:15, 11.39s/it]Training:   1%|          | 5/471 [00:18<25:23,  3.27s/it]  Training:   1%|▏         | 6/471 [00:19<19:50,  2.56s/it]Training:   1%|▏         | 7/471 [00:19<15:13,  1.97s/it]Training:   2%|▏         | 9/471 [00:26<21:10,  2.75s/it]Training:   2%|▏         | 10/471 [00:27<16:51,  2.20s/it]Training:   2%|▏         | 11/471 [00:27<13:14,  1.73s/it]Training:   3%|▎         | 13/471 [00:34<19:19,  2.53s/it]Training:   3%|▎         | 14/471 [00:35<15:34,  2.05s/it]Training:   3%|▎         | 15/471 [00:35<12:16,  1.61s/it]Training:   4%|▎         | 17/471 [00:43<18:58,  2.51s/it]Training:   4%|▍         | 19/471 [00:43<12:42,  1.69s/it]Training:   4%|▍         | 21/471 [00:51<18:00,  2.40s/it]Training:   5%|▍         | 23/471 [00:51<12:41,  1.70s/it]Training:   5%|▌         | 25/471 [00:58<17:03,  2.29s/it]Training:   6%|▌         | 27/471 [00:59<12:08,  1.64s/it]Training:   6%|▌         | 29/471 [01:07<17:07,  2.32s/it]Training:   6%|▋         | 30/471 [01:07<14:07,  1.92s/it]Training:   7%|▋         | 31/471 [01:07<12:07,  1.65s/it]Training:   7%|▋         | 33/471 [01:14<17:14,  2.36s/it]Training:   7%|▋         | 34/471 [01:15<14:05,  1.93s/it]Training:   7%|▋         | 35/471 [01:15<11:43,  1.61s/it]Training:   8%|▊         | 37/471 [01:23<17:39,  2.44s/it]Training:   8%|▊         | 39/471 [01:23<11:47,  1.64s/it]Training:   9%|▊         | 41/471 [01:33<20:05,  2.80s/it]Training:   9%|▉         | 42/471 [01:33<16:21,  2.29s/it]Training:   9%|▉         | 43/471 [01:34<13:39,  1.92s/it]Training:  10%|▉         | 45/471 [01:43<20:22,  2.87s/it]Training:  10%|▉         | 47/471 [01:43<13:51,  1.96s/it]Training:  10%|█         | 49/471 [01:53<20:30,  2.92s/it]Training:  11%|█         | 51/471 [01:53<14:10,  2.03s/it]Training:  11%|█▏        | 53/471 [02:03<20:23,  2.93s/it]Training:  12%|█▏        | 55/471 [02:04<14:31,  2.09s/it]Training:  12%|█▏        | 57/471 [02:13<20:02,  2.90s/it]Training:  13%|█▎        | 59/471 [02:14<14:43,  2.15s/it]Training:  13%|█▎        | 61/471 [02:23<19:56,  2.92s/it]Training:  13%|█▎        | 63/471 [02:24<14:35,  2.15s/it]Training:  14%|█▍        | 65/471 [02:32<18:36,  2.75s/it]Training:  14%|█▍        | 67/471 [02:33<13:20,  1.98s/it]Training:  15%|█▍        | 69/471 [02:40<16:19,  2.44s/it]Training:  15%|█▌        | 71/471 [02:40<11:53,  1.78s/it]Training:  15%|█▌        | 73/471 [02:48<15:37,  2.36s/it]Training:  16%|█▌        | 75/471 [02:48<11:13,  1.70s/it]Training:  16%|█▋        | 77/471 [02:55<14:57,  2.28s/it]Training:  17%|█▋        | 79/471 [02:55<10:43,  1.64s/it]Training:  17%|█▋        | 80/471 [02:56<08:58,  1.38s/it]Training:  17%|█▋        | 81/471 [03:03<16:45,  2.58s/it]Training:  18%|█▊        | 83/471 [03:03<11:11,  1.73s/it]Training:  18%|█▊        | 84/471 [03:04<09:33,  1.48s/it]Training:  18%|█▊        | 85/471 [03:11<17:31,  2.72s/it]Training:  18%|█▊        | 87/471 [03:12<11:22,  1.78s/it]Training:  19%|█▊        | 88/471 [03:12<09:29,  1.49s/it]Training:  19%|█▉        | 89/471 [03:20<18:48,  2.95s/it]Training:  19%|█▉        | 91/471 [03:20<11:52,  1.88s/it]Training:  20%|█▉        | 92/471 [03:21<10:08,  1.61s/it]Training:  20%|█▉        | 93/471 [03:29<19:20,  3.07s/it]Training:  20%|██        | 95/471 [03:29<11:59,  1.91s/it]Training:  20%|██        | 96/471 [03:30<10:31,  1.68s/it]Training:  21%|██        | 97/471 [03:38<20:24,  3.27s/it]Training:  21%|██        | 99/471 [03:39<13:09,  2.12s/it]Training:  21%|██        | 100/471 [03:40<11:21,  1.84s/it]Training:  21%|██▏       | 101/471 [03:48<21:29,  3.48s/it]Training:  22%|██▏       | 103/471 [03:49<13:43,  2.24s/it]Training:  22%|██▏       | 104/471 [03:50<11:57,  1.95s/it]Training:  22%|██▏       | 105/471 [03:58<20:59,  3.44s/it]Training:  23%|██▎       | 107/471 [04:01<15:45,  2.60s/it]Training:  23%|██▎       | 108/471 [04:02<13:02,  2.16s/it]Training:  23%|██▎       | 109/471 [04:11<22:56,  3.80s/it]Training:  24%|██▎       | 111/471 [04:12<15:07,  2.52s/it]Training:  24%|██▍       | 112/471 [04:13<12:30,  2.09s/it]Training:  24%|██▍       | 113/471 [04:22<22:20,  3.74s/it]Training:  24%|██▍       | 115/471 [04:23<14:35,  2.46s/it]Training:  25%|██▍       | 116/471 [04:23<12:02,  2.03s/it]Training:  25%|██▍       | 117/471 [04:33<22:16,  3.78s/it]Training:  25%|██▌       | 119/471 [04:34<15:04,  2.57s/it]Training:  25%|██▌       | 120/471 [04:35<12:09,  2.08s/it]Training:  26%|██▌       | 121/471 [04:44<22:02,  3.78s/it]Training:  26%|██▌       | 123/471 [04:45<14:54,  2.57s/it]Training:  26%|██▋       | 124/471 [04:46<12:27,  2.15s/it]Training:  27%|██▋       | 125/471 [04:55<21:41,  3.76s/it]Training:  27%|██▋       | 127/471 [04:56<14:27,  2.52s/it]Training:  27%|██▋       | 128/471 [04:57<11:56,  2.09s/it]Training:  27%|██▋       | 129/471 [05:05<20:17,  3.56s/it]Training:  28%|██▊       | 131/471 [05:07<13:47,  2.43s/it]Training:  28%|██▊       | 132/471 [05:08<11:45,  2.08s/it]Training:  28%|██▊       | 133/471 [05:16<20:54,  3.71s/it]Training:  29%|██▊       | 135/471 [05:18<13:58,  2.49s/it]Training:  29%|██▉       | 136/471 [05:19<11:47,  2.11s/it]Training:  29%|██▉       | 137/471 [05:27<20:49,  3.74s/it]Training:  30%|██▉       | 139/471 [05:29<13:54,  2.51s/it]Training:  30%|██▉       | 140/471 [05:30<11:38,  2.11s/it]Training:  30%|██▉       | 141/471 [05:38<20:33,  3.74s/it]Training:  30%|███       | 143/471 [05:40<14:20,  2.62s/it]Training:  31%|███       | 144/471 [05:41<11:52,  2.18s/it]Training:  31%|███       | 145/471 [05:50<21:02,  3.87s/it]Training:  31%|███       | 147/471 [05:52<14:38,  2.71s/it]Training:  31%|███▏      | 148/471 [05:53<11:59,  2.23s/it]Training:  32%|███▏      | 149/471 [06:02<20:47,  3.87s/it]Training:  32%|███▏      | 151/471 [06:04<14:07,  2.65s/it]Training:  32%|███▏      | 152/471 [06:04<11:35,  2.18s/it]Training:  32%|███▏      | 153/471 [06:13<20:14,  3.82s/it]Training:  33%|███▎      | 155/471 [06:15<13:41,  2.60s/it]Training:  33%|███▎      | 156/471 [06:15<11:13,  2.14s/it]Training:  33%|███▎      | 157/471 [06:24<19:41,  3.76s/it]Training:  34%|███▍      | 159/471 [06:26<13:21,  2.57s/it]Training:  34%|███▍      | 160/471 [06:26<11:02,  2.13s/it]Training:  34%|███▍      | 161/471 [06:35<19:35,  3.79s/it]Training:  35%|███▍      | 163/471 [06:37<13:19,  2.59s/it]Training:  35%|███▍      | 164/471 [06:37<10:30,  2.05s/it]Training:  35%|███▌      | 165/471 [06:47<19:23,  3.80s/it]Training:  35%|███▌      | 167/471 [06:48<12:55,  2.55s/it]Training:  36%|███▌      | 168/471 [06:48<10:06,  2.00s/it]Training:  36%|███▌      | 169/471 [06:58<19:11,  3.81s/it]Training:  36%|███▋      | 171/471 [06:59<12:56,  2.59s/it]Training:  37%|███▋      | 172/471 [07:00<10:11,  2.05s/it]Training:  37%|███▋      | 173/471 [07:08<17:56,  3.61s/it]Training:  37%|███▋      | 175/471 [07:12<14:30,  2.94s/it]Training:  38%|███▊      | 177/471 [07:19<15:53,  3.24s/it]Training:  38%|███▊      | 179/471 [07:23<13:13,  2.72s/it]Training:  38%|███▊      | 181/471 [07:30<14:48,  3.06s/it]Training:  39%|███▉      | 183/471 [07:34<12:47,  2.66s/it]Training:  39%|███▉      | 185/471 [07:41<13:59,  2.93s/it]Training:  40%|███▉      | 187/471 [07:45<12:21,  2.61s/it]Training:  40%|████      | 189/471 [07:56<16:12,  3.45s/it]Training:  41%|████      | 191/471 [07:59<13:43,  2.94s/it]Training:  41%|████      | 193/471 [08:06<14:11,  3.06s/it]Training:  41%|████▏     | 195/471 [08:10<12:39,  2.75s/it]Training:  42%|████▏     | 197/471 [08:16<13:07,  2.87s/it]Training:  42%|████▏     | 199/471 [08:20<11:46,  2.60s/it]Training:  43%|████▎     | 201/471 [08:26<12:10,  2.71s/it]Training:  43%|████▎     | 203/471 [08:30<11:16,  2.52s/it]Training:  43%|████▎     | 204/471 [08:34<12:36,  2.83s/it]Training:  44%|████▎     | 205/471 [08:36<11:08,  2.51s/it]Training:  44%|████▍     | 207/471 [08:44<13:49,  3.14s/it]Training:  44%|████▍     | 208/471 [08:44<11:04,  2.53s/it]Training:  44%|████▍     | 209/471 [08:46<10:14,  2.34s/it]Training:  45%|████▍     | 211/471 [08:54<13:17,  3.07s/it]Training:  45%|████▌     | 212/471 [08:55<10:36,  2.46s/it]Training:  45%|████▌     | 213/471 [08:56<09:30,  2.21s/it]Training:  46%|████▌     | 215/471 [09:05<12:54,  3.03s/it]Training:  46%|████▌     | 216/471 [09:05<10:04,  2.37s/it]Training:  46%|████▌     | 217/471 [09:06<09:17,  2.19s/it]Training:  46%|████▋     | 219/471 [09:15<13:00,  3.10s/it]Training:  47%|████▋     | 220/471 [09:15<10:07,  2.42s/it]Training:  47%|████▋     | 221/471 [09:17<09:35,  2.30s/it]Training:  47%|████▋     | 223/471 [09:26<13:07,  3.18s/it]Training:  48%|████▊     | 225/471 [09:28<09:35,  2.34s/it]Training:  48%|████▊     | 227/471 [09:37<12:32,  3.08s/it]Training:  49%|████▊     | 229/471 [09:39<09:39,  2.39s/it]Training:  49%|████▉     | 231/471 [09:47<11:50,  2.96s/it]Training:  49%|████▉     | 233/471 [09:49<09:20,  2.36s/it]Training:  50%|████▉     | 235/471 [09:58<11:27,  2.91s/it]Training:  50%|█████     | 237/471 [10:00<09:05,  2.33s/it]Training:  51%|█████     | 239/471 [10:08<11:20,  2.93s/it]Training:  51%|█████     | 240/471 [10:08<09:24,  2.44s/it]Training:  51%|█████     | 241/471 [10:10<08:53,  2.32s/it]Training:  52%|█████▏    | 243/471 [10:19<11:39,  3.07s/it]Training:  52%|█████▏    | 244/471 [10:19<09:23,  2.48s/it]Training:  52%|█████▏    | 245/471 [10:21<08:45,  2.32s/it]Training:  52%|█████▏    | 247/471 [10:30<11:44,  3.14s/it]Training:  53%|█████▎    | 248/471 [10:30<09:25,  2.54s/it]Training:  53%|█████▎    | 249/471 [10:32<08:32,  2.31s/it]Training:  53%|█████▎    | 251/471 [10:41<11:51,  3.23s/it]Training:  54%|█████▎    | 252/471 [10:41<09:30,  2.61s/it]Training:  54%|█████▎    | 253/471 [10:43<08:25,  2.32s/it]Training:  54%|█████▍    | 255/471 [10:51<11:07,  3.09s/it]Training:  54%|█████▍    | 256/471 [10:52<09:17,  2.59s/it]Training:  55%|█████▍    | 257/471 [10:53<08:07,  2.28s/it]Training:  55%|█████▍    | 259/471 [11:02<10:47,  3.05s/it]Training:  55%|█████▌    | 260/471 [11:03<09:01,  2.57s/it]Training:  55%|█████▌    | 261/471 [11:04<07:41,  2.20s/it]Training:  56%|█████▌    | 263/471 [11:12<10:40,  3.08s/it]Training:  56%|█████▌    | 264/471 [11:14<09:15,  2.68s/it]Training:  56%|█████▋    | 265/471 [11:14<07:32,  2.20s/it]Training:  57%|█████▋    | 267/471 [11:23<10:21,  3.05s/it]Training:  57%|█████▋    | 268/471 [11:24<08:59,  2.66s/it]Training:  57%|█████▋    | 269/471 [11:25<07:15,  2.16s/it]Training:  58%|█████▊    | 271/471 [11:34<10:40,  3.20s/it]Training:  58%|█████▊    | 272/471 [11:35<09:00,  2.71s/it]Training:  58%|█████▊    | 273/471 [11:36<07:27,  2.26s/it]Training:  58%|█████▊    | 275/471 [11:45<10:03,  3.08s/it]Training:  59%|█████▊    | 276/471 [11:46<08:34,  2.64s/it]Training:  59%|█████▉    | 277/471 [11:47<07:20,  2.27s/it]Training:  59%|█████▉    | 279/471 [11:55<09:48,  3.06s/it]Training:  59%|█████▉    | 280/471 [11:57<08:27,  2.65s/it]Training:  60%|█████▉    | 281/471 [11:58<07:15,  2.29s/it]Training:  60%|██████    | 283/471 [12:06<09:32,  3.05s/it]Training:  60%|██████    | 284/471 [12:08<08:33,  2.75s/it]Training:  61%|██████    | 285/471 [12:09<07:09,  2.31s/it]Training:  61%|██████    | 287/471 [12:17<09:25,  3.07s/it]Training:  61%|██████    | 288/471 [12:19<08:25,  2.76s/it]Training:  61%|██████▏   | 289/471 [12:20<07:05,  2.34s/it]Training:  62%|██████▏   | 291/471 [12:28<09:18,  3.10s/it]Training:  62%|██████▏   | 292/471 [12:30<08:23,  2.81s/it]Training:  62%|██████▏   | 293/471 [12:31<06:59,  2.35s/it]Training:  63%|██████▎   | 295/471 [12:39<08:46,  2.99s/it]Training:  63%|██████▎   | 296/471 [12:41<08:01,  2.75s/it]Training:  63%|██████▎   | 297/471 [12:41<06:30,  2.25s/it]Training:  63%|██████▎   | 299/471 [12:49<08:25,  2.94s/it]Training:  64%|██████▎   | 300/471 [12:51<07:38,  2.68s/it]Training:  64%|██████▍   | 301/471 [12:52<06:43,  2.38s/it]Training:  64%|██████▍   | 303/471 [12:59<07:33,  2.70s/it]Training:  65%|██████▍   | 304/471 [13:00<06:43,  2.41s/it]Training:  65%|██████▍   | 305/471 [13:01<05:49,  2.11s/it]Training:  65%|██████▌   | 307/471 [13:06<06:14,  2.28s/it]Training:  65%|██████▌   | 308/471 [13:08<05:36,  2.06s/it]Training:  66%|██████▌   | 309/471 [13:09<04:59,  1.85s/it]Training:  66%|██████▌   | 311/471 [13:14<05:39,  2.12s/it]Training:  66%|██████▌   | 312/471 [13:15<05:09,  1.95s/it]Training:  66%|██████▋   | 313/471 [13:17<04:57,  1.88s/it]Training:  67%|██████▋   | 315/471 [13:22<05:44,  2.21s/it]Training:  67%|██████▋   | 316/471 [13:24<05:04,  1.96s/it]Training:  67%|██████▋   | 317/471 [13:25<04:58,  1.94s/it]Training:  68%|██████▊   | 319/471 [13:31<05:45,  2.27s/it]Training:  68%|██████▊   | 320/471 [13:32<05:05,  2.02s/it]Training:  68%|██████▊   | 321/471 [13:34<04:57,  1.98s/it]Training:  69%|██████▊   | 323/471 [13:40<05:43,  2.32s/it]Training:  69%|██████▉   | 324/471 [13:41<04:56,  2.02s/it]Training:  69%|██████▉   | 325/471 [13:42<04:46,  1.96s/it]Training:  69%|██████▉   | 327/471 [13:47<05:14,  2.19s/it]Training:  70%|██████▉   | 328/471 [13:48<04:37,  1.94s/it]Training:  70%|██████▉   | 329/471 [13:50<04:34,  1.93s/it]Training:  70%|███████   | 331/471 [13:56<05:17,  2.27s/it]Training:  70%|███████   | 332/471 [13:57<04:38,  2.00s/it]Training:  71%|███████   | 333/471 [13:59<04:36,  2.00s/it]Training:  71%|███████   | 335/471 [14:05<05:25,  2.40s/it]Training:  71%|███████▏  | 336/471 [14:06<04:47,  2.13s/it]Training:  72%|███████▏  | 337/471 [14:08<04:53,  2.19s/it]Training:  72%|███████▏  | 339/471 [14:15<05:40,  2.58s/it]Training:  72%|███████▏  | 340/471 [14:16<04:51,  2.23s/it]Training:  72%|███████▏  | 341/471 [14:18<04:44,  2.19s/it]Training:  73%|███████▎  | 343/471 [14:24<05:28,  2.57s/it]Training:  73%|███████▎  | 344/471 [14:25<04:51,  2.29s/it]Training:  73%|███████▎  | 345/471 [14:28<04:46,  2.27s/it]Training:  74%|███████▎  | 347/471 [14:34<05:30,  2.67s/it]Training:  74%|███████▍  | 348/471 [14:36<04:59,  2.44s/it]Training:  74%|███████▍  | 349/471 [14:38<04:50,  2.38s/it]Training:  75%|███████▍  | 351/471 [14:44<05:13,  2.61s/it]Training:  75%|███████▍  | 352/471 [14:45<04:41,  2.36s/it]Training:  75%|███████▍  | 353/471 [14:48<04:49,  2.45s/it]Training:  75%|███████▌  | 355/471 [14:54<05:06,  2.64s/it]Training:  76%|███████▌  | 356/471 [14:56<04:37,  2.42s/it]Training:  76%|███████▌  | 357/471 [14:58<04:43,  2.49s/it]Training:  76%|███████▌  | 359/471 [15:04<04:51,  2.60s/it]Training:  76%|███████▋  | 360/471 [15:06<04:27,  2.41s/it]Training:  77%|███████▋  | 361/471 [15:08<04:28,  2.44s/it]Training:  77%|███████▋  | 363/471 [15:14<04:42,  2.62s/it]Training:  77%|███████▋  | 364/471 [15:15<04:16,  2.40s/it]Training:  77%|███████▋  | 365/471 [15:18<04:06,  2.33s/it]Training:  78%|███████▊  | 367/471 [15:23<04:24,  2.54s/it]Training:  78%|███████▊  | 368/471 [15:25<04:07,  2.41s/it]Training:  78%|███████▊  | 369/471 [15:27<03:58,  2.34s/it]Training:  79%|███████▉  | 371/471 [15:34<04:24,  2.64s/it]Training:  79%|███████▉  | 372/471 [15:35<04:02,  2.45s/it]Training:  79%|███████▉  | 373/471 [15:37<03:49,  2.34s/it]Training:  80%|███████▉  | 375/471 [15:43<04:12,  2.63s/it]Training:  80%|███████▉  | 376/471 [15:45<03:52,  2.45s/it]Training:  80%|████████  | 377/471 [15:47<03:40,  2.35s/it]Training:  80%|████████  | 379/471 [15:53<03:59,  2.61s/it]Training:  81%|████████  | 380/471 [15:55<03:38,  2.40s/it]Training:  81%|████████  | 381/471 [15:57<03:35,  2.40s/it]Training:  81%|████████▏ | 383/471 [16:03<03:55,  2.68s/it]Training:  82%|████████▏ | 384/471 [16:05<03:35,  2.47s/it]Training:  82%|████████▏ | 385/471 [16:08<03:31,  2.46s/it]Training:  82%|████████▏ | 387/471 [16:14<03:46,  2.70s/it]Training:  82%|████████▏ | 388/471 [16:15<03:23,  2.45s/it]Training:  83%|████████▎ | 389/471 [16:18<03:28,  2.55s/it]Training:  83%|████████▎ | 391/471 [16:24<03:36,  2.71s/it]Training:  83%|████████▎ | 392/471 [16:26<03:15,  2.48s/it]Training:  83%|████████▎ | 393/471 [16:28<03:17,  2.53s/it]Training:  84%|████████▍ | 395/471 [16:34<03:19,  2.63s/it]Training:  84%|████████▍ | 396/471 [16:36<03:12,  2.56s/it]Training:  84%|████████▍ | 397/471 [16:39<03:12,  2.60s/it]Training:  85%|████████▍ | 399/471 [16:45<03:16,  2.73s/it]Training:  85%|████████▍ | 400/471 [16:47<03:06,  2.62s/it]Training:  85%|████████▌ | 401/471 [16:50<03:03,  2.63s/it]Training:  86%|████████▌ | 403/471 [16:55<03:03,  2.70s/it]Training:  86%|████████▌ | 404/471 [16:57<02:51,  2.55s/it]Training:  86%|████████▌ | 405/471 [17:00<02:46,  2.53s/it]Training:  86%|████████▋ | 407/471 [17:05<02:48,  2.63s/it]Training:  87%|████████▋ | 408/471 [17:08<02:39,  2.53s/it]Training:  87%|████████▋ | 409/471 [17:10<02:39,  2.58s/it]Training:  87%|████████▋ | 411/471 [17:16<02:42,  2.71s/it]Training:  87%|████████▋ | 412/471 [17:18<02:31,  2.57s/it]Training:  88%|████████▊ | 413/471 [17:21<02:30,  2.59s/it]Training:  88%|████████▊ | 415/471 [17:27<02:31,  2.71s/it]Training:  88%|████████▊ | 416/471 [17:28<02:17,  2.50s/it]Training:  89%|████████▊ | 417/471 [17:31<02:14,  2.49s/it]Training:  89%|████████▉ | 419/471 [17:37<02:16,  2.63s/it]Training:  89%|████████▉ | 420/471 [17:39<02:11,  2.58s/it]Training:  89%|████████▉ | 421/471 [17:41<02:08,  2.57s/it]Training:  90%|████████▉ | 423/471 [17:47<02:05,  2.62s/it]Training:  90%|█████████ | 424/471 [17:49<01:57,  2.49s/it]Training:  90%|█████████ | 425/471 [17:52<01:56,  2.54s/it]Training:  91%|█████████ | 427/471 [17:57<01:57,  2.68s/it]Training:  91%|█████████ | 428/471 [17:59<01:48,  2.53s/it]Training:  91%|█████████ | 429/471 [18:02<01:50,  2.63s/it]Training:  92%|█████████▏| 431/471 [18:08<01:45,  2.64s/it]Training:  92%|█████████▏| 432/471 [18:10<01:36,  2.47s/it]Training:  92%|█████████▏| 433/471 [18:13<01:40,  2.65s/it]Training:  92%|█████████▏| 435/471 [18:18<01:35,  2.66s/it]Training:  93%|█████████▎| 436/471 [18:20<01:28,  2.53s/it]Training:  93%|█████████▎| 437/471 [18:23<01:32,  2.71s/it]Training:  93%|█████████▎| 439/471 [18:29<01:28,  2.78s/it]Training:  93%|█████████▎| 440/471 [18:31<01:18,  2.53s/it]Training:  94%|█████████▎| 441/471 [18:34<01:17,  2.58s/it]Training:  94%|█████████▍| 443/471 [18:40<01:18,  2.80s/it]Training:  94%|█████████▍| 444/471 [18:41<01:07,  2.48s/it]Training:  94%|█████████▍| 445/471 [18:44<01:07,  2.59s/it]Training:  95%|█████████▍| 447/471 [18:51<01:09,  2.90s/it]Training:  95%|█████████▌| 448/471 [18:52<00:58,  2.55s/it]Training:  95%|█████████▌| 449/471 [18:55<01:00,  2.73s/it]Training:  96%|█████████▌| 451/471 [19:02<00:59,  2.98s/it]Training:  96%|█████████▌| 452/471 [19:04<00:49,  2.63s/it]Training:  96%|█████████▌| 453/471 [19:07<00:49,  2.74s/it]Training:  97%|█████████▋| 455/471 [19:13<00:46,  2.89s/it]Training:  97%|█████████▋| 456/471 [19:14<00:38,  2.54s/it]Training:  97%|█████████▋| 457/471 [19:18<00:38,  2.73s/it]Training:  97%|█████████▋| 459/471 [19:23<00:33,  2.83s/it]Training:  98%|█████████▊| 460/471 [19:25<00:26,  2.45s/it]Training:  98%|█████████▊| 461/471 [19:28<00:27,  2.76s/it]Training:  98%|█████████▊| 463/471 [19:34<00:22,  2.85s/it]Training:  99%|█████████▊| 464/471 [19:36<00:17,  2.50s/it]Training:  99%|█████████▊| 465/471 [19:39<00:15,  2.65s/it]Training:  99%|█████████▉| 467/471 [19:45<00:11,  2.94s/it]Training:  99%|█████████▉| 468/471 [19:47<00:07,  2.56s/it]Training: 100%|█████████▉| 469/471 [19:49<00:05,  2.54s/it]Training: 100%|██████████| 471/471 [19:50<00:00,  1.62s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Training: 100%|██████████| 471/471 [19:50<00:00,  2.53s/it]
Evaluating:   0%|          | 0/118 [00:00<?, ?it/s]Evaluating:   1%|          | 1/118 [00:11<21:37, 11.09s/it]Evaluating:   3%|▎         | 4/118 [00:11<04:04,  2.14s/it]Evaluating:   5%|▌         | 6/118 [00:22<06:56,  3.72s/it]Evaluating:   7%|▋         | 8/118 [00:23<04:19,  2.36s/it]Evaluating:   8%|▊         | 10/118 [00:31<05:17,  2.94s/it]Evaluating:   9%|▉         | 11/118 [00:31<04:15,  2.39s/it]Evaluating:  11%|█         | 13/118 [00:39<05:12,  2.98s/it]Evaluating:  13%|█▎        | 15/118 [00:39<03:27,  2.01s/it]Evaluating:  14%|█▍        | 17/118 [00:47<04:31,  2.69s/it]Evaluating:  17%|█▋        | 20/118 [00:47<02:36,  1.60s/it]Evaluating:  18%|█▊        | 21/118 [00:56<04:23,  2.71s/it]Evaluating:  19%|█▊        | 22/118 [00:56<03:33,  2.23s/it]Evaluating:  20%|██        | 24/118 [00:56<02:19,  1.49s/it]Evaluating:  21%|██        | 25/118 [01:06<04:48,  3.10s/it]Evaluating:  23%|██▎       | 27/118 [01:07<03:15,  2.14s/it]Evaluating:  25%|██▍       | 29/118 [01:16<04:19,  2.92s/it]Evaluating:  26%|██▋       | 31/118 [01:17<03:08,  2.17s/it]Evaluating:  28%|██▊       | 33/118 [01:26<04:06,  2.90s/it]Evaluating:  30%|██▉       | 35/118 [01:27<02:59,  2.16s/it]Evaluating:  31%|███▏      | 37/118 [01:36<03:50,  2.85s/it]Evaluating:  33%|███▎      | 39/118 [01:36<02:45,  2.09s/it]Evaluating:  35%|███▍      | 41/118 [01:44<03:20,  2.61s/it]Evaluating:  36%|███▌      | 42/118 [01:46<03:09,  2.49s/it]Evaluating:  38%|███▊      | 45/118 [01:53<02:57,  2.43s/it]Evaluating:  39%|███▉      | 46/118 [01:55<02:52,  2.39s/it]Evaluating:  42%|████▏     | 49/118 [02:02<02:44,  2.38s/it]Evaluating:  42%|████▏     | 50/118 [02:05<02:43,  2.41s/it]Evaluating:  45%|████▍     | 53/118 [02:12<02:37,  2.42s/it]Evaluating:  46%|████▌     | 54/118 [02:14<02:35,  2.42s/it]Evaluating:  48%|████▊     | 57/118 [02:22<02:27,  2.42s/it]Evaluating:  49%|████▉     | 58/118 [02:25<02:29,  2.49s/it]Evaluating:  52%|█████▏    | 61/118 [02:32<02:19,  2.45s/it]Evaluating:  53%|█████▎    | 62/118 [02:35<02:23,  2.56s/it]Evaluating:  55%|█████▌    | 65/118 [02:42<02:13,  2.52s/it]Evaluating:  56%|█████▌    | 66/118 [02:46<02:19,  2.69s/it]Evaluating:  58%|█████▊    | 69/118 [02:53<02:04,  2.55s/it]Evaluating:  59%|█████▉    | 70/118 [02:56<02:09,  2.71s/it]Evaluating:  62%|██████▏   | 73/118 [03:05<02:04,  2.77s/it]Evaluating:  63%|██████▎   | 74/118 [03:08<02:02,  2.78s/it]Evaluating:  65%|██████▌   | 77/118 [03:15<01:48,  2.65s/it]Evaluating:  66%|██████▌   | 78/118 [03:18<01:49,  2.74s/it]Evaluating:  69%|██████▊   | 81/118 [03:26<01:37,  2.63s/it]Evaluating:  69%|██████▉   | 82/118 [03:29<01:39,  2.76s/it]Evaluating:  72%|███████▏  | 85/118 [03:38<01:33,  2.83s/it]Evaluating:  73%|███████▎  | 86/118 [03:41<01:34,  2.94s/it]Evaluating:  75%|███████▌  | 89/118 [03:49<01:19,  2.74s/it]Evaluating:  76%|███████▋  | 90/118 [03:53<01:21,  2.91s/it]Evaluating:  79%|███████▉  | 93/118 [03:59<01:05,  2.62s/it]Evaluating:  80%|███████▉  | 94/118 [04:03<01:08,  2.86s/it]Evaluating:  82%|████████▏ | 97/118 [04:10<00:53,  2.57s/it]Evaluating:  83%|████████▎ | 98/118 [04:14<00:56,  2.81s/it]Evaluating:  86%|████████▌ | 101/118 [04:20<00:42,  2.52s/it]Evaluating:  86%|████████▋ | 102/118 [04:25<00:45,  2.84s/it]Evaluating:  89%|████████▉ | 105/118 [04:31<00:33,  2.55s/it]Evaluating:  90%|████████▉ | 106/118 [04:36<00:34,  2.88s/it]Evaluating:  92%|█████████▏| 109/118 [04:42<00:23,  2.57s/it]Evaluating:  93%|█████████▎| 110/118 [04:47<00:23,  2.91s/it]Evaluating:  96%|█████████▌| 113/118 [04:53<00:13,  2.64s/it]Evaluating:  97%|█████████▋| 114/118 [04:57<00:11,  2.76s/it]Evaluating:  99%|█████████▉| 117/118 [05:01<00:02,  2.21s/it]Evaluating: 100%|██████████| 118/118 [05:02<00:00,  1.93s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Evaluating: 100%|██████████| 118/118 [05:02<00:00,  2.56s/it]
/home2/s439765/.conda/envs/yolov8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training:   0%|          | 0/471 [00:00<?, ?it/s]Training:   0%|          | 1/471 [00:11<1:29:37, 11.44s/it]Training:   1%|          | 4/471 [00:11<17:07,  2.20s/it]  Training:   1%|▏         | 7/471 [00:22<22:26,  2.90s/it]Training:   2%|▏         | 9/471 [00:33<29:29,  3.83s/it]Training:   2%|▏         | 11/471 [00:33<20:14,  2.64s/it]Training:   3%|▎         | 13/471 [00:45<27:58,  3.67s/it]Training:   3%|▎         | 15/471 [00:47<21:29,  2.83s/it]Training:   4%|▎         | 17/471 [00:56<25:22,  3.35s/it]Training:   4%|▍         | 19/471 [00:58<19:46,  2.63s/it]Training:   4%|▍         | 21/471 [01:07<23:50,  3.18s/it]Training:   5%|▍         | 23/471 [01:09<18:46,  2.52s/it]Training:   5%|▌         | 25/471 [01:18<23:23,  3.15s/it]Training:   6%|▌         | 27/471 [01:20<18:32,  2.51s/it]Training:   6%|▌         | 29/471 [01:29<23:15,  3.16s/it]Training:   7%|▋         | 31/471 [01:31<18:13,  2.49s/it]Training:   7%|▋         | 33/471 [01:41<22:53,  3.14s/it]Training:   7%|▋         | 35/471 [01:43<18:09,  2.50s/it]Training:   8%|▊         | 37/471 [01:51<22:13,  3.07s/it]Training:   8%|▊         | 39/471 [01:54<17:46,  2.47s/it]Training:   9%|▊         | 41/471 [02:03<22:09,  3.09s/it]Training:   9%|▉         | 43/471 [02:05<17:35,  2.47s/it]Training:  10%|▉         | 45/471 [02:13<21:36,  3.04s/it]Training:  10%|▉         | 47/471 [02:15<16:58,  2.40s/it]Training:  10%|█         | 49/471 [02:24<21:30,  3.06s/it]Training:  11%|█         | 51/471 [02:26<17:00,  2.43s/it]Training:  11%|█▏        | 53/471 [02:35<21:11,  3.04s/it]Training:  12%|█▏        | 55/471 [02:37<16:29,  2.38s/it]Training:  12%|█▏        | 57/471 [02:46<20:49,  3.02s/it]Training:  12%|█▏        | 58/471 [02:46<17:41,  2.57s/it]Training:  13%|█▎        | 59/471 [02:48<15:53,  2.32s/it]Training:  13%|█▎        | 61/471 [02:57<21:17,  3.12s/it]Training:  13%|█▎        | 62/471 [02:57<17:51,  2.62s/it]Training:  13%|█▎        | 63/471 [02:59<15:56,  2.34s/it]Training:  14%|█▍        | 65/471 [03:08<21:30,  3.18s/it]Training:  14%|█▍        | 66/471 [03:08<17:35,  2.61s/it]Training:  14%|█▍        | 67/471 [03:10<15:49,  2.35s/it]Training:  15%|█▍        | 69/471 [03:19<21:06,  3.15s/it]Training:  15%|█▍        | 70/471 [03:19<17:12,  2.57s/it]Training:  15%|█▌        | 71/471 [03:21<15:47,  2.37s/it]Training:  15%|█▌        | 73/471 [03:29<20:58,  3.16s/it]Training:  16%|█▌        | 74/471 [03:30<17:19,  2.62s/it]Training:  16%|█▌        | 75/471 [03:31<14:36,  2.21s/it]Training:  16%|█▋        | 77/471 [03:37<17:01,  2.59s/it]Training:  17%|█▋        | 78/471 [03:38<13:59,  2.14s/it]Training:  17%|█▋        | 79/471 [03:39<12:28,  1.91s/it]Training:  17%|█▋        | 81/471 [03:45<15:29,  2.38s/it]Training:  17%|█▋        | 82/471 [03:46<12:34,  1.94s/it]Training:  18%|█▊        | 83/471 [03:47<11:11,  1.73s/it]Training:  18%|█▊        | 85/471 [03:54<15:53,  2.47s/it]Training:  18%|█▊        | 86/471 [03:54<12:39,  1.97s/it]Training:  18%|█▊        | 87/471 [03:56<11:53,  1.86s/it]Training:  19%|█▉        | 89/471 [04:03<16:46,  2.64s/it]Training:  19%|█▉        | 90/471 [04:03<13:10,  2.08s/it]Training:  19%|█▉        | 91/471 [04:06<13:18,  2.10s/it]Training:  20%|█▉        | 93/471 [04:13<17:36,  2.79s/it]Training:  20%|██        | 95/471 [04:15<13:23,  2.14s/it]Training:  21%|██        | 97/471 [04:23<16:50,  2.70s/it]Training:  21%|██        | 98/471 [04:23<13:41,  2.20s/it]Training:  21%|██        | 99/471 [04:25<13:04,  2.11s/it]Training:  21%|██▏       | 101/471 [04:32<17:15,  2.80s/it]Training:  22%|██▏       | 102/471 [04:33<13:52,  2.26s/it]Training:  22%|██▏       | 103/471 [04:35<13:13,  2.16s/it]Training:  22%|██▏       | 105/471 [04:42<17:28,  2.86s/it]Training:  23%|██▎       | 107/471 [04:44<12:38,  2.08s/it]Training:  23%|██▎       | 109/471 [04:51<15:53,  2.63s/it]Training:  24%|██▎       | 111/471 [04:53<11:57,  1.99s/it]Training:  24%|██▍       | 113/471 [05:01<15:37,  2.62s/it]Training:  24%|██▍       | 115/471 [05:03<12:40,  2.13s/it]Training:  25%|██▍       | 117/471 [05:11<16:10,  2.74s/it]Training:  25%|██▌       | 119/471 [05:13<13:06,  2.24s/it]Training:  26%|██▌       | 121/471 [05:21<16:12,  2.78s/it]Training:  26%|██▌       | 123/471 [05:23<13:08,  2.26s/it]Training:  27%|██▋       | 125/471 [05:31<16:12,  2.81s/it]Training:  27%|██▋       | 127/471 [05:34<13:20,  2.33s/it]Training:  27%|██▋       | 129/471 [05:42<16:01,  2.81s/it]Training:  28%|██▊       | 131/471 [05:44<13:16,  2.34s/it]Training:  28%|██▊       | 133/471 [05:52<15:53,  2.82s/it]Training:  28%|██▊       | 134/471 [05:53<13:37,  2.43s/it]Training:  29%|██▊       | 135/471 [05:55<13:29,  2.41s/it]Training:  29%|██▉       | 137/471 [06:02<16:07,  2.90s/it]Training:  29%|██▉       | 138/471 [06:03<13:37,  2.45s/it]Training:  30%|██▉       | 139/471 [06:06<13:34,  2.45s/it]Training:  30%|██▉       | 141/471 [06:13<16:09,  2.94s/it]Training:  30%|███       | 142/471 [06:14<13:26,  2.45s/it]Training:  30%|███       | 143/471 [06:16<13:42,  2.51s/it]Training:  31%|███       | 145/471 [06:24<16:32,  3.04s/it]Training:  31%|███       | 146/471 [06:25<13:28,  2.49s/it]Training:  31%|███       | 147/471 [06:27<13:28,  2.49s/it]Training:  32%|███▏      | 149/471 [06:35<16:40,  3.11s/it]Training:  32%|███▏      | 150/471 [06:36<13:26,  2.51s/it]Training:  32%|███▏      | 151/471 [06:38<13:21,  2.50s/it]Training:  32%|███▏      | 153/471 [06:46<16:14,  3.06s/it]Training:  33%|███▎      | 154/471 [06:46<12:56,  2.45s/it]Training:  33%|███▎      | 155/471 [06:49<12:47,  2.43s/it]Training:  33%|███▎      | 157/471 [06:57<16:02,  3.07s/it]Training:  34%|███▎      | 158/471 [06:57<13:02,  2.50s/it]Training:  34%|███▍      | 159/471 [06:59<12:29,  2.40s/it]Training:  34%|███▍      | 161/471 [07:07<15:40,  3.03s/it]Training:  34%|███▍      | 162/471 [07:08<13:11,  2.56s/it]Training:  35%|███▍      | 163/471 [07:10<12:29,  2.43s/it]Training:  35%|███▌      | 165/471 [07:18<16:03,  3.15s/it]Training:  35%|███▌      | 166/471 [07:19<13:04,  2.57s/it]Training:  35%|███▌      | 167/471 [07:21<12:32,  2.47s/it]Training:  36%|███▌      | 169/471 [07:29<15:04,  3.00s/it]Training:  36%|███▌      | 170/471 [07:29<12:20,  2.46s/it]Training:  36%|███▋      | 171/471 [07:31<11:50,  2.37s/it]Training:  37%|███▋      | 173/471 [07:39<14:34,  2.93s/it]Training:  37%|███▋      | 174/471 [07:40<11:56,  2.41s/it]Training:  37%|███▋      | 175/471 [07:42<11:24,  2.31s/it]Training:  38%|███▊      | 177/471 [07:50<14:43,  3.00s/it]Training:  38%|███▊      | 178/471 [07:50<11:54,  2.44s/it]Training:  38%|███▊      | 179/471 [07:52<11:30,  2.37s/it]Training:  38%|███▊      | 181/471 [08:00<14:29,  3.00s/it]Training:  39%|███▊      | 182/471 [08:01<11:44,  2.44s/it]Training:  39%|███▉      | 183/471 [08:03<11:40,  2.43s/it]Training:  39%|███▉      | 185/471 [08:11<14:48,  3.11s/it]Training:  39%|███▉      | 186/471 [08:12<11:52,  2.50s/it]Training:  40%|███▉      | 187/471 [08:14<11:43,  2.48s/it]Training:  40%|████      | 189/471 [08:22<14:33,  3.10s/it]Training:  40%|████      | 190/471 [08:22<11:46,  2.52s/it]Training:  41%|████      | 191/471 [08:25<11:29,  2.46s/it]Training:  41%|████      | 193/471 [08:33<14:19,  3.09s/it]Training:  41%|████      | 194/471 [08:34<11:54,  2.58s/it]Training:  41%|████▏     | 195/471 [08:36<11:16,  2.45s/it]Training:  42%|████▏     | 197/471 [08:44<14:44,  3.23s/it]Training:  42%|████▏     | 198/471 [08:45<11:58,  2.63s/it]Training:  42%|████▏     | 199/471 [08:47<11:12,  2.47s/it]Training:  43%|████▎     | 201/471 [08:55<14:24,  3.20s/it]Training:  43%|████▎     | 202/471 [08:56<11:48,  2.63s/it]Training:  43%|████▎     | 203/471 [08:58<11:02,  2.47s/it]Training:  44%|████▎     | 205/471 [09:06<14:05,  3.18s/it]Training:  44%|████▎     | 206/471 [09:07<11:50,  2.68s/it]Training:  44%|████▍     | 207/471 [09:09<10:47,  2.45s/it]Training:  44%|████▍     | 209/471 [09:18<13:50,  3.17s/it]Training:  45%|████▍     | 210/471 [09:18<11:34,  2.66s/it]Training:  45%|████▍     | 211/471 [09:20<10:39,  2.46s/it]Training:  45%|████▌     | 213/471 [09:28<13:05,  3.05s/it]Training:  45%|████▌     | 214/471 [09:29<11:05,  2.59s/it]Training:  46%|████▌     | 215/471 [09:31<10:08,  2.38s/it]Training:  46%|████▌     | 217/471 [09:39<12:47,  3.02s/it]Training:  46%|████▋     | 218/471 [09:40<11:07,  2.64s/it]Training:  46%|████▋     | 219/471 [09:42<10:08,  2.42s/it]Training:  47%|████▋     | 221/471 [09:49<12:23,  2.97s/it]Training:  47%|████▋     | 222/471 [09:50<10:24,  2.51s/it]Training:  47%|████▋     | 223/471 [09:52<09:38,  2.33s/it]Training:  48%|████▊     | 225/471 [10:00<12:41,  3.10s/it]Training:  48%|████▊     | 226/471 [10:01<10:41,  2.62s/it]Training:  48%|████▊     | 227/471 [10:03<09:50,  2.42s/it]Training:  49%|████▊     | 229/471 [10:12<12:46,  3.17s/it]Training:  49%|████▉     | 230/471 [10:12<10:26,  2.60s/it]Training:  49%|████▉     | 231/471 [10:14<09:37,  2.41s/it]Training:  49%|████▉     | 233/471 [10:22<12:12,  3.08s/it]Training:  50%|████▉     | 234/471 [10:23<10:23,  2.63s/it]Training:  50%|████▉     | 235/471 [10:25<09:44,  2.48s/it]Training:  50%|█████     | 237/471 [10:33<12:11,  3.13s/it]Training:  51%|█████     | 238/471 [10:35<10:28,  2.70s/it]Training:  51%|█████     | 239/471 [10:37<10:10,  2.63s/it]Training:  51%|█████     | 241/471 [10:44<11:45,  3.07s/it]Training:  51%|█████▏    | 242/471 [10:46<10:06,  2.65s/it]Training:  52%|█████▏    | 243/471 [10:48<09:35,  2.52s/it]Training:  52%|█████▏    | 245/471 [10:55<11:25,  3.03s/it]Training:  52%|█████▏    | 246/471 [10:57<09:46,  2.61s/it]Training:  52%|█████▏    | 247/471 [10:59<09:25,  2.53s/it]Training:  53%|█████▎    | 249/471 [11:06<11:17,  3.05s/it]Training:  53%|█████▎    | 250/471 [11:08<09:36,  2.61s/it]Training:  53%|█████▎    | 251/471 [11:10<09:22,  2.56s/it]Training:  54%|█████▎    | 253/471 [11:17<11:07,  3.06s/it]Training:  54%|█████▍    | 254/471 [11:19<09:36,  2.66s/it]Training:  54%|█████▍    | 255/471 [11:21<09:19,  2.59s/it]Training:  55%|█████▍    | 257/471 [11:29<10:55,  3.06s/it]Training:  55%|█████▍    | 258/471 [11:30<09:34,  2.70s/it]Training:  55%|█████▍    | 259/471 [11:32<09:06,  2.58s/it]Training:  55%|█████▌    | 261/471 [11:40<10:42,  3.06s/it]Training:  56%|█████▌    | 262/471 [11:41<09:22,  2.69s/it]Training:  56%|█████▌    | 263/471 [11:43<08:49,  2.55s/it]Training:  56%|█████▋    | 265/471 [11:51<10:42,  3.12s/it]Training:  56%|█████▋    | 266/471 [11:53<09:18,  2.72s/it]Training:  57%|█████▋    | 267/471 [11:54<08:30,  2.50s/it]Training:  57%|█████▋    | 269/471 [12:02<10:21,  3.08s/it]Training:  57%|█████▋    | 270/471 [12:04<09:11,  2.74s/it]Training:  58%|█████▊    | 271/471 [12:06<08:21,  2.51s/it]Training:  58%|█████▊    | 273/471 [12:14<10:18,  3.13s/it]Training:  58%|█████▊    | 274/471 [12:15<09:06,  2.78s/it]Training:  58%|█████▊    | 275/471 [12:17<07:58,  2.44s/it]Training:  59%|█████▉    | 277/471 [12:25<09:55,  3.07s/it]Training:  59%|█████▉    | 278/471 [12:26<08:30,  2.65s/it]Training:  59%|█████▉    | 279/471 [12:27<07:08,  2.23s/it]Training:  60%|█████▉    | 281/471 [12:33<08:14,  2.60s/it]Training:  60%|█████▉    | 282/471 [12:34<07:13,  2.29s/it]Training:  60%|██████    | 283/471 [12:35<06:08,  1.96s/it]Training:  61%|██████    | 285/471 [12:42<07:53,  2.55s/it]Training:  61%|██████    | 286/471 [12:43<06:54,  2.24s/it]Training:  61%|██████    | 287/471 [12:44<05:50,  1.91s/it]Training:  61%|██████▏   | 289/471 [12:52<08:11,  2.70s/it]Training:  62%|██████▏   | 290/471 [12:53<07:07,  2.36s/it]Training:  62%|██████▏   | 291/471 [12:54<06:03,  2.02s/it]Training:  62%|██████▏   | 293/471 [13:02<08:22,  2.82s/it]Training:  62%|██████▏   | 294/471 [13:03<07:19,  2.49s/it]Training:  63%|██████▎   | 295/471 [13:04<06:08,  2.09s/it]Training:  63%|██████▎   | 297/471 [13:12<08:22,  2.89s/it]Training:  63%|██████▎   | 298/471 [13:13<07:17,  2.53s/it]Training:  63%|██████▎   | 299/471 [13:14<06:17,  2.19s/it]Training:  64%|██████▍   | 301/471 [13:23<08:22,  2.96s/it]Training:  64%|██████▍   | 302/471 [13:24<07:38,  2.71s/it]Training:  64%|██████▍   | 303/471 [13:25<06:19,  2.26s/it]Training:  65%|██████▍   | 305/471 [13:34<08:28,  3.06s/it]Training:  65%|██████▍   | 306/471 [13:36<07:48,  2.84s/it]Training:  65%|██████▌   | 307/471 [13:37<06:32,  2.39s/it]Training:  66%|██████▌   | 309/471 [13:45<08:05,  2.99s/it]Training:  66%|██████▌   | 310/471 [13:47<07:36,  2.84s/it]Training:  66%|██████▌   | 311/471 [13:48<06:18,  2.36s/it]Training:  66%|██████▋   | 313/471 [13:56<08:03,  3.06s/it]Training:  67%|██████▋   | 314/471 [13:58<07:20,  2.81s/it]Training:  67%|██████▋   | 315/471 [13:59<06:00,  2.31s/it]Training:  67%|██████▋   | 317/471 [14:07<07:40,  2.99s/it]Training:  68%|██████▊   | 318/471 [14:09<07:13,  2.83s/it]Training:  68%|██████▊   | 319/471 [14:10<05:57,  2.35s/it]Training:  68%|██████▊   | 321/471 [14:17<07:01,  2.81s/it]Training:  68%|██████▊   | 322/471 [14:19<06:56,  2.80s/it]Training:  69%|██████▊   | 323/471 [14:20<05:43,  2.32s/it]Training:  69%|██████▉   | 325/471 [14:27<06:33,  2.70s/it]Training:  69%|██████▉   | 326/471 [14:30<06:38,  2.75s/it]Training:  69%|██████▉   | 327/471 [14:30<05:26,  2.27s/it]Training:  70%|██████▉   | 329/471 [14:37<06:19,  2.67s/it]Training:  70%|███████   | 330/471 [14:40<06:16,  2.67s/it]Training:  70%|███████   | 331/471 [14:40<05:07,  2.20s/it]Training:  71%|███████   | 333/471 [14:50<07:30,  3.26s/it]Training:  71%|███████   | 334/471 [14:51<06:18,  2.77s/it]Training:  71%|███████   | 335/471 [14:51<04:52,  2.15s/it]Training:  72%|███████▏  | 337/471 [15:01<07:08,  3.20s/it]Training:  72%|███████▏  | 338/471 [15:01<05:47,  2.61s/it]Training:  72%|███████▏  | 339/471 [15:02<04:32,  2.07s/it]Training:  72%|███████▏  | 341/471 [15:11<06:42,  3.09s/it]Training:  73%|███████▎  | 342/471 [15:12<05:37,  2.61s/it]Training:  73%|███████▎  | 345/471 [15:21<05:58,  2.85s/it]Training:  73%|███████▎  | 346/471 [15:22<05:15,  2.53s/it]Training:  74%|███████▍  | 349/471 [15:32<05:43,  2.81s/it]Training:  74%|███████▍  | 350/471 [15:33<05:06,  2.53s/it]Training:  75%|███████▍  | 353/471 [15:42<05:24,  2.75s/it]Training:  75%|███████▌  | 354/471 [15:43<04:57,  2.55s/it]Training:  76%|███████▌  | 357/471 [15:53<05:16,  2.78s/it]Training:  76%|███████▌  | 358/471 [15:55<04:55,  2.61s/it]Training:  77%|███████▋  | 361/471 [16:04<05:13,  2.85s/it]Training:  77%|███████▋  | 362/471 [16:06<04:49,  2.66s/it]Training:  77%|███████▋  | 365/471 [16:15<04:58,  2.82s/it]Training:  78%|███████▊  | 366/471 [16:17<04:42,  2.69s/it]Training:  78%|███████▊  | 369/471 [16:26<04:49,  2.84s/it]Training:  79%|███████▊  | 370/471 [16:28<04:29,  2.67s/it]Training:  79%|███████▉  | 373/471 [16:37<04:36,  2.82s/it]Training:  79%|███████▉  | 374/471 [16:39<04:18,  2.67s/it]Training:  80%|████████  | 377/471 [16:48<04:23,  2.80s/it]Training:  80%|████████  | 378/471 [16:50<04:12,  2.71s/it]Training:  81%|████████  | 381/471 [16:59<04:12,  2.81s/it]Training:  81%|████████  | 382/471 [17:01<04:01,  2.72s/it]Training:  82%|████████▏ | 385/471 [17:10<04:03,  2.83s/it]Training:  82%|████████▏ | 386/471 [17:12<03:46,  2.66s/it]Training:  83%|████████▎ | 389/471 [17:21<03:50,  2.82s/it]Training:  83%|████████▎ | 390/471 [17:22<03:28,  2.57s/it]Training:  83%|████████▎ | 393/471 [17:32<03:44,  2.88s/it]Training:  84%|████████▎ | 394/471 [17:33<03:18,  2.58s/it]Training:  84%|████████▍ | 397/471 [17:44<03:34,  2.90s/it]Training:  85%|████████▍ | 398/471 [17:45<03:10,  2.61s/it]Training:  85%|████████▌ | 401/471 [17:54<03:18,  2.84s/it]Training:  85%|████████▌ | 402/471 [17:55<02:54,  2.53s/it]Training:  86%|████████▌ | 405/471 [18:05<03:04,  2.79s/it]Training:  86%|████████▌ | 406/471 [18:06<02:43,  2.51s/it]Training:  87%|████████▋ | 409/471 [18:15<02:52,  2.78s/it]Training:  87%|████████▋ | 410/471 [18:17<02:35,  2.55s/it]Training:  88%|████████▊ | 413/471 [18:26<02:45,  2.85s/it]Training:  88%|████████▊ | 414/471 [18:28<02:28,  2.60s/it]Training:  89%|████████▊ | 417/471 [18:37<02:34,  2.86s/it]Training:  89%|████████▊ | 418/471 [18:39<02:17,  2.59s/it]Training:  89%|████████▉ | 421/471 [18:48<02:20,  2.80s/it]Training:  90%|████████▉ | 422/471 [18:49<02:03,  2.53s/it]Training:  90%|█████████ | 425/471 [18:59<02:10,  2.84s/it]Training:  90%|█████████ | 426/471 [19:00<01:53,  2.52s/it]Training:  91%|█████████ | 429/471 [19:10<01:58,  2.82s/it]Training:  91%|█████████▏| 430/471 [19:11<01:43,  2.53s/it]Training:  92%|█████████▏| 433/471 [19:20<01:47,  2.82s/it]Training:  92%|█████████▏| 434/471 [19:21<01:34,  2.55s/it]Training:  93%|█████████▎| 437/471 [19:32<01:40,  2.95s/it]Training:  93%|█████████▎| 438/471 [19:33<01:25,  2.60s/it]Training:  94%|█████████▎| 441/471 [19:43<01:28,  2.95s/it]Training:  94%|█████████▍| 442/471 [19:44<01:14,  2.57s/it]Training:  94%|█████████▍| 445/471 [19:54<01:15,  2.92s/it]Training:  95%|█████████▍| 446/471 [19:55<01:03,  2.54s/it]Training:  95%|█████████▌| 449/471 [20:05<01:02,  2.85s/it]Training:  96%|█████████▌| 450/471 [20:05<00:51,  2.44s/it]Training:  96%|█████████▌| 451/471 [20:05<00:39,  2.00s/it]Training:  96%|█████████▌| 453/471 [20:15<00:54,  3.05s/it]Training:  96%|█████████▋| 454/471 [20:16<00:44,  2.59s/it]Training:  97%|█████████▋| 457/471 [20:26<00:40,  2.93s/it]Training:  97%|█████████▋| 458/471 [20:27<00:33,  2.58s/it]Training:  98%|█████████▊| 461/471 [20:37<00:30,  3.02s/it]Training:  98%|█████████▊| 462/471 [20:38<00:22,  2.53s/it]Training:  99%|█████████▊| 465/471 [20:48<00:17,  2.96s/it]Training: 100%|█████████▉| 469/471 [20:57<00:05,  2.61s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Training: 100%|██████████| 471/471 [20:57<00:00,  2.67s/it]
Evaluating:   0%|          | 0/118 [00:00<?, ?it/s]Evaluating:   1%|          | 1/118 [00:11<21:34, 11.06s/it]Evaluating:   2%|▏         | 2/118 [00:11<09:11,  4.76s/it]Evaluating:   4%|▍         | 5/118 [00:21<07:02,  3.74s/it]Evaluating:   5%|▌         | 6/118 [00:22<05:32,  2.97s/it]Evaluating:   8%|▊         | 9/118 [00:32<05:52,  3.23s/it]Evaluating:   8%|▊         | 10/118 [00:33<04:53,  2.72s/it]Evaluating:  11%|█         | 13/118 [00:43<05:16,  3.01s/it]Evaluating:  12%|█▏        | 14/118 [00:43<04:26,  2.56s/it]Evaluating:  14%|█▎        | 16/118 [00:43<02:56,  1.73s/it]Evaluating:  14%|█▍        | 17/118 [00:54<05:40,  3.37s/it]Evaluating:  15%|█▌        | 18/118 [00:54<04:35,  2.75s/it]Evaluating:  18%|█▊        | 21/118 [01:05<05:11,  3.21s/it]Evaluating:  19%|█▊        | 22/118 [01:06<04:18,  2.70s/it]Evaluating:  21%|██        | 25/118 [01:16<04:42,  3.04s/it]Evaluating:  22%|██▏       | 26/118 [01:16<03:55,  2.56s/it]Evaluating:  25%|██▍       | 29/118 [01:27<04:22,  2.95s/it]Evaluating:  25%|██▌       | 30/118 [01:27<03:40,  2.50s/it]Evaluating:  28%|██▊       | 33/118 [01:38<04:11,  2.96s/it]Evaluating:  31%|███       | 36/118 [01:38<02:34,  1.88s/it]Evaluating:  31%|███▏      | 37/118 [01:49<04:16,  3.17s/it]Evaluating:  32%|███▏      | 38/118 [01:49<03:31,  2.64s/it]Evaluating:  34%|███▍      | 40/118 [01:49<02:21,  1.82s/it]Evaluating:  35%|███▍      | 41/118 [01:57<03:57,  3.08s/it]Evaluating:  36%|███▌      | 42/118 [01:58<03:05,  2.44s/it]Evaluating:  37%|███▋      | 44/118 [01:58<01:55,  1.56s/it]Evaluating:  38%|███▊      | 45/118 [02:05<03:25,  2.82s/it]Evaluating:  39%|███▉      | 46/118 [02:06<02:39,  2.21s/it]Evaluating:  41%|████      | 48/118 [02:06<01:36,  1.38s/it]Evaluating:  42%|████▏     | 49/118 [02:14<03:18,  2.88s/it]Evaluating:  42%|████▏     | 50/118 [02:14<02:32,  2.24s/it]Evaluating:  44%|████▍     | 52/118 [02:15<01:32,  1.41s/it]Evaluating:  45%|████▍     | 53/118 [02:23<03:10,  2.94s/it]Evaluating:  46%|████▌     | 54/118 [02:23<02:26,  2.29s/it]Evaluating:  47%|████▋     | 56/118 [02:24<01:33,  1.51s/it]Evaluating:  48%|████▊     | 57/118 [02:32<03:10,  3.12s/it]Evaluating:  49%|████▉     | 58/118 [02:33<02:32,  2.54s/it]Evaluating:  51%|█████     | 60/118 [02:34<01:32,  1.60s/it]Evaluating:  52%|█████▏    | 61/118 [02:43<03:12,  3.38s/it]Evaluating:  53%|█████▎    | 62/118 [02:44<02:38,  2.82s/it]Evaluating:  54%|█████▍    | 64/118 [02:45<01:33,  1.73s/it]Evaluating:  55%|█████▌    | 65/118 [02:53<02:57,  3.35s/it]Evaluating:  56%|█████▌    | 66/118 [02:55<02:28,  2.85s/it]Evaluating:  58%|█████▊    | 68/118 [02:55<01:28,  1.77s/it]Evaluating:  58%|█████▊    | 69/118 [03:06<03:02,  3.73s/it]Evaluating:  59%|█████▉    | 70/118 [03:07<02:32,  3.19s/it]Evaluating:  61%|██████    | 72/118 [03:07<01:29,  1.95s/it]Evaluating:  62%|██████▏   | 73/118 [03:16<02:40,  3.56s/it]Evaluating:  63%|██████▎   | 74/118 [03:18<02:13,  3.02s/it]Evaluating:  64%|██████▍   | 76/118 [03:18<01:19,  1.89s/it]Evaluating:  65%|██████▌   | 77/118 [03:27<02:17,  3.35s/it]Evaluating:  66%|██████▌   | 78/118 [03:28<01:55,  2.89s/it]Evaluating:  68%|██████▊   | 80/118 [03:29<01:08,  1.81s/it]Evaluating:  69%|██████▊   | 81/118 [03:37<02:02,  3.30s/it]Evaluating:  69%|██████▉   | 82/118 [03:39<01:42,  2.84s/it]Evaluating:  71%|███████   | 84/118 [03:39<01:01,  1.82s/it]Evaluating:  72%|███████▏  | 85/118 [03:48<01:52,  3.39s/it]Evaluating:  73%|███████▎  | 86/118 [03:50<01:34,  2.95s/it]Evaluating:  75%|███████▍  | 88/118 [03:50<00:55,  1.85s/it]Evaluating:  75%|███████▌  | 89/118 [03:59<01:38,  3.41s/it]Evaluating:  76%|███████▋  | 90/118 [04:01<01:26,  3.09s/it]Evaluating:  78%|███████▊  | 92/118 [04:01<00:48,  1.88s/it]Evaluating:  79%|███████▉  | 93/118 [04:09<01:22,  3.30s/it]Evaluating:  80%|███████▉  | 94/118 [04:11<01:11,  2.96s/it]Evaluating:  81%|████████▏ | 96/118 [04:12<00:41,  1.87s/it]Evaluating:  82%|████████▏ | 97/118 [04:20<01:07,  3.23s/it]Evaluating:  83%|████████▎ | 98/118 [04:22<00:59,  2.99s/it]Evaluating:  85%|████████▍ | 100/118 [04:23<00:33,  1.88s/it]Evaluating:  86%|████████▌ | 101/118 [04:31<00:57,  3.37s/it]Evaluating:  86%|████████▋ | 102/118 [04:33<00:48,  3.01s/it]Evaluating:  88%|████████▊ | 104/118 [04:34<00:26,  1.93s/it]Evaluating:  89%|████████▉ | 105/118 [04:42<00:43,  3.36s/it]Evaluating:  90%|████████▉ | 106/118 [04:44<00:35,  2.93s/it]Evaluating:  92%|█████████▏| 108/118 [04:44<00:18,  1.89s/it]Evaluating:  92%|█████████▏| 109/118 [04:52<00:29,  3.30s/it]Evaluating:  93%|█████████▎| 110/118 [04:55<00:24,  3.03s/it]Evaluating:  95%|█████████▍| 112/118 [04:55<00:11,  1.94s/it]Evaluating:  96%|█████████▌| 113/118 [05:04<00:16,  3.36s/it]Evaluating:  97%|█████████▋| 114/118 [05:06<00:12,  3.13s/it]Evaluating:  98%|█████████▊| 116/118 [05:06<00:03,  1.90s/it]Evaluating:  99%|█████████▉| 117/118 [05:12<00:02,  2.77s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Evaluating: 100%|██████████| 118/118 [05:12<00:00,  2.65s/it]
/home2/s439765/.conda/envs/yolov8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training:   0%|          | 0/471 [00:00<?, ?it/s]Training:   0%|          | 1/471 [00:10<1:25:49, 10.96s/it]Training:   0%|          | 2/471 [00:11<36:07,  4.62s/it]  Training:   1%|          | 5/471 [00:21<29:16,  3.77s/it]Training:   1%|▏         | 6/471 [00:21<22:43,  2.93s/it]Training:   2%|▏         | 9/471 [00:32<25:30,  3.31s/it]Training:   2%|▏         | 10/471 [00:33<20:37,  2.69s/it]Training:   3%|▎         | 12/471 [00:33<13:42,  1.79s/it]Training:   3%|▎         | 13/471 [00:43<27:16,  3.57s/it]Training:   3%|▎         | 14/471 [00:44<21:42,  2.85s/it]Training:   3%|▎         | 16/471 [00:44<13:20,  1.76s/it]Training:   4%|▎         | 17/471 [00:55<28:09,  3.72s/it]Training:   4%|▍         | 18/471 [00:55<21:45,  2.88s/it]Training:   4%|▍         | 19/471 [00:55<16:33,  2.20s/it]Training:   4%|▍         | 20/471 [00:55<12:41,  1.69s/it]Training:   4%|▍         | 21/471 [01:05<29:33,  3.94s/it]Training:   5%|▍         | 22/471 [01:06<22:07,  2.96s/it]Training:   5%|▌         | 24/471 [01:06<12:44,  1.71s/it]Training:   5%|▌         | 25/471 [01:16<27:36,  3.71s/it]Training:   6%|▌         | 26/471 [01:16<20:40,  2.79s/it]Training:   6%|▌         | 28/471 [01:17<12:34,  1.70s/it]Training:   6%|▌         | 29/471 [01:27<27:34,  3.74s/it]Training:   6%|▋         | 30/471 [01:27<21:02,  2.86s/it]Training:   7%|▋         | 32/471 [01:28<12:53,  1.76s/it]Training:   7%|▋         | 33/471 [01:38<27:27,  3.76s/it]Training:   7%|▋         | 34/471 [01:38<21:07,  2.90s/it]Training:   8%|▊         | 36/471 [01:39<13:11,  1.82s/it]Training:   8%|▊         | 37/471 [01:50<28:09,  3.89s/it]Training:   8%|▊         | 38/471 [01:50<21:42,  3.01s/it]Training:   8%|▊         | 40/471 [01:51<13:49,  1.92s/it]Training:   9%|▊         | 41/471 [02:01<27:07,  3.79s/it]Training:   9%|▉         | 42/471 [02:02<21:24,  2.99s/it]Training:   9%|▉         | 44/471 [02:02<13:08,  1.85s/it]Training:  10%|▉         | 45/471 [02:12<26:43,  3.77s/it]Training:  10%|▉         | 46/471 [02:13<21:35,  3.05s/it]Training:  10%|█         | 48/471 [02:14<13:11,  1.87s/it]Training:  10%|█         | 49/471 [02:24<26:38,  3.79s/it]Training:  11%|█         | 50/471 [02:24<21:02,  3.00s/it]Training:  11%|█         | 52/471 [02:25<12:59,  1.86s/it]Training:  11%|█▏        | 53/471 [02:35<26:11,  3.76s/it]Training:  11%|█▏        | 54/471 [02:36<20:54,  3.01s/it]Training:  12%|█▏        | 56/471 [02:36<12:33,  1.82s/it]Training:  12%|█▏        | 57/471 [02:46<25:04,  3.63s/it]Training:  12%|█▏        | 58/471 [02:47<20:37,  3.00s/it]Training:  13%|█▎        | 60/471 [02:47<12:28,  1.82s/it]Training:  13%|█▎        | 61/471 [02:57<25:02,  3.66s/it]Training:  13%|█▎        | 62/471 [02:58<20:40,  3.03s/it]Training:  14%|█▍        | 65/471 [03:08<21:31,  3.18s/it]Training:  14%|█▍        | 66/471 [03:09<18:35,  2.76s/it]Training:  15%|█▍        | 69/471 [03:19<20:07,  3.00s/it]Training:  15%|█▍        | 70/471 [03:20<17:45,  2.66s/it]Training:  15%|█▌        | 73/471 [03:30<19:48,  2.99s/it]Training:  16%|█▌        | 74/471 [03:32<17:41,  2.68s/it]Training:  16%|█▋        | 77/471 [03:42<19:38,  2.99s/it]Training:  17%|█▋        | 78/471 [03:43<17:41,  2.70s/it]Training:  17%|█▋        | 81/471 [03:53<19:04,  2.93s/it]Training:  17%|█▋        | 82/471 [03:54<17:26,  2.69s/it]Training:  18%|█▊        | 85/471 [04:04<19:07,  2.97s/it]Training:  18%|█▊        | 86/471 [04:06<17:18,  2.70s/it]Training:  19%|█▉        | 89/471 [04:16<18:48,  2.95s/it]Training:  19%|█▉        | 90/471 [04:17<16:42,  2.63s/it]Training:  20%|█▉        | 93/471 [04:28<19:13,  3.05s/it]Training:  20%|█▉        | 94/471 [04:29<16:59,  2.70s/it]Training:  21%|██        | 97/471 [04:39<18:47,  3.02s/it]Training:  21%|██        | 98/471 [04:40<16:39,  2.68s/it]Training:  21%|██▏       | 101/471 [04:50<18:01,  2.92s/it]Training:  22%|██▏       | 102/471 [04:51<16:12,  2.64s/it]Training:  22%|██▏       | 105/471 [05:01<17:54,  2.94s/it]Training:  23%|██▎       | 106/471 [05:02<16:21,  2.69s/it]Training:  23%|██▎       | 109/471 [05:13<18:07,  3.00s/it]Training:  23%|██▎       | 110/471 [05:14<16:28,  2.74s/it]Training:  24%|██▍       | 113/471 [05:24<17:54,  3.00s/it]Training:  24%|██▍       | 114/471 [05:26<16:15,  2.73s/it]Training:  25%|██▍       | 117/471 [05:35<17:06,  2.90s/it]Training:  25%|██▌       | 118/471 [05:37<15:53,  2.70s/it]Training:  26%|██▌       | 121/471 [05:46<16:48,  2.88s/it]Training:  26%|██▌       | 122/471 [05:48<15:51,  2.73s/it]Training:  27%|██▋       | 125/471 [05:58<17:09,  2.98s/it]Training:  27%|██▋       | 126/471 [06:00<15:49,  2.75s/it]Training:  27%|██▋       | 129/471 [06:07<14:58,  2.63s/it]Training:  28%|██▊       | 130/471 [06:08<13:17,  2.34s/it]Training:  28%|██▊       | 133/471 [06:15<13:14,  2.35s/it]Training:  28%|██▊       | 134/471 [06:16<12:15,  2.18s/it]Training:  29%|██▉       | 137/471 [06:25<13:38,  2.45s/it]Training:  29%|██▉       | 138/471 [06:26<12:43,  2.29s/it]Training:  30%|██▉       | 141/471 [06:35<14:03,  2.56s/it]Training:  30%|███       | 142/471 [06:37<13:15,  2.42s/it]Training:  31%|███       | 145/471 [06:46<14:37,  2.69s/it]Training:  31%|███       | 146/471 [06:48<13:30,  2.49s/it]Training:  32%|███▏      | 149/471 [06:57<14:50,  2.77s/it]Training:  32%|███▏      | 150/471 [06:58<13:32,  2.53s/it]Training:  32%|███▏      | 153/471 [07:08<15:09,  2.86s/it]Training:  33%|███▎      | 154/471 [07:10<13:58,  2.64s/it]Training:  33%|███▎      | 157/471 [07:20<15:02,  2.87s/it]Training:  34%|███▎      | 158/471 [07:21<13:47,  2.65s/it]Training:  34%|███▍      | 161/471 [07:31<15:06,  2.92s/it]Training:  34%|███▍      | 162/471 [07:33<13:56,  2.71s/it]Training:  35%|███▌      | 165/471 [07:42<14:24,  2.83s/it]Training:  35%|███▌      | 166/471 [07:44<13:50,  2.72s/it]Training:  36%|███▌      | 169/471 [07:52<14:00,  2.78s/it]Training:  36%|███▌      | 170/471 [07:55<13:33,  2.70s/it]Training:  37%|███▋      | 173/471 [08:04<14:14,  2.87s/it]Training:  37%|███▋      | 174/471 [08:06<13:36,  2.75s/it]Training:  38%|███▊      | 177/471 [08:15<13:46,  2.81s/it]Training:  38%|███▊      | 178/471 [08:17<13:07,  2.69s/it]Training:  38%|███▊      | 181/471 [08:26<13:33,  2.81s/it]Training:  39%|███▊      | 182/471 [08:28<12:53,  2.68s/it]Training:  39%|███▉      | 185/471 [08:36<13:07,  2.75s/it]Training:  39%|███▉      | 186/471 [08:38<12:22,  2.61s/it]Training:  40%|████      | 189/471 [08:48<13:14,  2.82s/it]Training:  40%|████      | 190/471 [08:55<17:00,  3.63s/it]Training:  41%|████      | 193/471 [08:58<11:49,  2.55s/it]Training:  41%|████      | 194/471 [09:07<15:58,  3.46s/it]Training:  42%|████▏     | 197/471 [09:10<11:15,  2.47s/it]Training:  42%|████▏     | 198/471 [09:18<15:16,  3.36s/it]Training:  43%|████▎     | 201/471 [09:21<10:48,  2.40s/it]Training:  43%|████▎     | 202/471 [09:29<15:13,  3.40s/it]Training:  44%|████▎     | 205/471 [09:32<10:33,  2.38s/it]Training:  44%|████▎     | 206/471 [09:40<14:56,  3.38s/it]Training:  44%|████▍     | 209/471 [09:43<10:17,  2.36s/it]Training:  45%|████▍     | 210/471 [09:51<14:27,  3.33s/it]Training:  45%|████▌     | 213/471 [09:54<09:50,  2.29s/it]Training:  45%|████▌     | 214/471 [10:02<14:12,  3.32s/it]Training:  46%|████▌     | 217/471 [10:05<09:31,  2.25s/it]Training:  46%|████▋     | 218/471 [10:13<13:48,  3.28s/it]Training:  47%|████▋     | 221/471 [10:16<09:22,  2.25s/it]Training:  47%|████▋     | 222/471 [10:24<13:31,  3.26s/it]Training:  48%|████▊     | 225/471 [10:27<09:28,  2.31s/it]Training:  48%|████▊     | 226/471 [10:35<13:32,  3.32s/it]Training:  49%|████▊     | 229/471 [10:38<09:31,  2.36s/it]Training:  49%|████▉     | 230/471 [10:47<13:38,  3.39s/it]Training:  49%|████▉     | 233/471 [10:50<09:43,  2.45s/it]Training:  50%|████▉     | 234/471 [10:58<13:11,  3.34s/it]Training:  50%|█████     | 237/471 [11:01<09:23,  2.41s/it]Training:  51%|█████     | 238/471 [11:09<12:56,  3.33s/it]Training:  51%|█████     | 241/471 [11:12<09:02,  2.36s/it]Training:  51%|█████▏    | 242/471 [11:21<12:51,  3.37s/it]Training:  52%|█████▏    | 245/471 [11:24<09:00,  2.39s/it]Training:  52%|█████▏    | 246/471 [11:32<12:21,  3.30s/it]Training:  53%|█████▎    | 249/471 [11:35<08:52,  2.40s/it]Training:  53%|█████▎    | 250/471 [11:43<12:19,  3.35s/it]Training:  54%|█████▎    | 253/471 [11:46<08:42,  2.40s/it]Training:  54%|█████▍    | 254/471 [11:54<12:03,  3.33s/it]Training:  55%|█████▍    | 257/471 [11:59<09:06,  2.55s/it]Training:  55%|█████▍    | 258/471 [12:07<12:11,  3.44s/it]Training:  55%|█████▌    | 261/471 [12:10<08:41,  2.48s/it]Training:  56%|█████▌    | 262/471 [12:18<11:38,  3.34s/it]Training:  56%|█████▋    | 265/471 [12:22<08:31,  2.48s/it]Training:  56%|█████▋    | 266/471 [12:29<11:28,  3.36s/it]Training:  57%|█████▋    | 269/471 [12:33<08:12,  2.44s/it]Training:  57%|█████▋    | 270/471 [12:40<10:58,  3.28s/it]Training:  58%|█████▊    | 273/471 [12:44<07:50,  2.38s/it]Training:  58%|█████▊    | 274/471 [12:52<10:57,  3.34s/it]Training:  59%|█████▉    | 277/471 [12:55<07:38,  2.36s/it]Training:  59%|█████▉    | 278/471 [13:03<10:37,  3.30s/it]Training:  60%|█████▉    | 281/471 [13:06<07:20,  2.32s/it]Training:  60%|█████▉    | 282/471 [13:14<10:18,  3.27s/it]Training:  61%|██████    | 285/471 [13:17<07:08,  2.30s/it]Training:  61%|██████    | 286/471 [13:25<10:03,  3.26s/it]Training:  61%|██████▏   | 289/471 [13:27<06:52,  2.27s/it]Training:  62%|██████▏   | 290/471 [13:35<09:38,  3.20s/it]Training:  62%|██████▏   | 293/471 [13:38<06:37,  2.23s/it]Training:  62%|██████▏   | 294/471 [13:46<09:40,  3.28s/it]Training:  63%|██████▎   | 297/471 [13:49<06:32,  2.26s/it]Training:  63%|██████▎   | 298/471 [13:58<09:36,  3.33s/it]Training:  64%|██████▍   | 301/471 [14:00<06:23,  2.25s/it]Training:  64%|██████▍   | 302/471 [14:08<09:19,  3.31s/it]Training:  65%|██████▍   | 305/471 [14:11<06:10,  2.23s/it]Training:  65%|██████▍   | 306/471 [14:19<09:03,  3.29s/it]Training:  66%|██████▌   | 309/471 [14:22<06:03,  2.25s/it]Training:  66%|██████▌   | 310/471 [14:30<08:51,  3.30s/it]Training:  66%|██████▋   | 313/471 [14:33<05:57,  2.26s/it]Training:  67%|██████▋   | 314/471 [14:41<08:36,  3.29s/it]Training:  67%|██████▋   | 317/471 [14:44<05:53,  2.29s/it]Training:  68%|██████▊   | 318/471 [14:51<08:03,  3.16s/it]Training:  68%|██████▊   | 321/471 [14:54<05:29,  2.19s/it]Training:  68%|██████▊   | 322/471 [15:02<07:44,  3.11s/it]Training:  69%|██████▉   | 325/471 [15:04<05:13,  2.14s/it]Training:  69%|██████▉   | 326/471 [15:12<07:31,  3.11s/it]Training:  70%|██████▉   | 329/471 [15:15<05:16,  2.23s/it]Training:  70%|███████   | 330/471 [15:23<07:22,  3.14s/it]Training:  71%|███████   | 333/471 [15:25<05:05,  2.22s/it]Training:  71%|███████   | 334/471 [15:33<07:13,  3.16s/it]Training:  72%|███████▏  | 337/471 [15:36<04:59,  2.24s/it]Training:  72%|███████▏  | 338/471 [15:44<06:58,  3.14s/it]Training:  72%|███████▏  | 341/471 [15:47<04:54,  2.27s/it]Training:  73%|███████▎  | 342/471 [15:55<06:56,  3.23s/it]Training:  73%|███████▎  | 345/471 [15:58<04:44,  2.26s/it]Training:  73%|███████▎  | 346/471 [16:06<06:42,  3.22s/it]Training:  74%|███████▍  | 349/471 [16:08<04:34,  2.25s/it]Training:  74%|███████▍  | 350/471 [16:16<06:29,  3.22s/it]Training:  75%|███████▍  | 353/471 [16:19<04:28,  2.27s/it]Training:  75%|███████▌  | 354/471 [16:27<06:05,  3.12s/it]Training:  76%|███████▌  | 357/471 [16:29<04:02,  2.13s/it]Training:  76%|███████▌  | 358/471 [16:35<05:09,  2.74s/it]Training:  77%|███████▋  | 361/471 [16:37<03:27,  1.89s/it]Training:  77%|███████▋  | 362/471 [16:43<04:45,  2.62s/it]Training:  77%|███████▋  | 365/471 [16:45<03:11,  1.81s/it]Training:  78%|███████▊  | 366/471 [16:51<04:23,  2.51s/it]Training:  78%|███████▊  | 369/471 [16:54<03:04,  1.81s/it]Training:  79%|███████▊  | 370/471 [17:00<04:19,  2.57s/it]Training:  79%|███████▉  | 373/471 [17:02<02:58,  1.82s/it]Training:  79%|███████▉  | 374/471 [17:09<04:13,  2.61s/it]Training:  80%|████████  | 377/471 [17:11<02:47,  1.78s/it]Training:  80%|████████  | 378/471 [17:18<04:12,  2.72s/it]Training:  81%|████████  | 381/471 [17:21<02:57,  1.98s/it]Training:  81%|████████  | 382/471 [17:28<04:14,  2.86s/it]Training:  82%|████████▏ | 385/471 [17:31<02:52,  2.01s/it]Training:  82%|████████▏ | 386/471 [17:38<04:06,  2.90s/it]Training:  83%|████████▎ | 389/471 [17:40<02:43,  1.99s/it]Training:  83%|████████▎ | 390/471 [17:48<03:56,  2.92s/it]Training:  83%|████████▎ | 393/471 [17:50<02:38,  2.03s/it]Training:  84%|████████▎ | 394/471 [17:58<03:46,  2.94s/it]Training:  84%|████████▍ | 397/471 [18:01<02:36,  2.11s/it]Training:  85%|████████▍ | 398/471 [18:09<03:45,  3.08s/it]Training:  85%|████████▌ | 401/471 [18:11<02:33,  2.19s/it]Training:  85%|████████▌ | 402/471 [18:19<03:35,  3.13s/it]Training:  86%|████████▌ | 405/471 [18:22<02:26,  2.21s/it]Training:  86%|████████▌ | 406/471 [18:30<03:22,  3.12s/it]Training:  87%|████████▋ | 409/471 [18:33<02:18,  2.23s/it]Training:  87%|████████▋ | 410/471 [18:40<03:11,  3.14s/it]Training:  88%|████████▊ | 413/471 [18:43<02:09,  2.23s/it]Training:  88%|████████▊ | 414/471 [18:52<03:05,  3.25s/it]Training:  89%|████████▊ | 417/471 [18:55<02:06,  2.35s/it]Training:  89%|████████▊ | 418/471 [19:02<02:47,  3.16s/it]Training:  89%|████████▉ | 421/471 [19:05<01:54,  2.30s/it]Training:  90%|████████▉ | 422/471 [19:13<02:33,  3.14s/it]Training:  90%|█████████ | 425/471 [19:16<01:42,  2.23s/it]Training:  90%|█████████ | 426/471 [19:23<02:19,  3.11s/it]Training:  91%|█████████ | 429/471 [19:26<01:34,  2.25s/it]Training:  91%|█████████▏| 430/471 [19:34<02:07,  3.11s/it]Training:  92%|█████████▏| 433/471 [19:37<01:24,  2.23s/it]Training:  92%|█████████▏| 434/471 [19:46<02:08,  3.47s/it]Training:  93%|█████████▎| 437/471 [19:49<01:18,  2.32s/it]Training:  93%|█████████▎| 438/471 [19:57<01:51,  3.37s/it]Training:  94%|█████████▎| 441/471 [19:59<01:07,  2.24s/it]Training:  94%|█████████▍| 442/471 [20:07<01:34,  3.25s/it]Training:  94%|█████████▍| 445/471 [20:09<00:56,  2.17s/it]Training:  95%|█████████▍| 446/471 [20:18<01:18,  3.14s/it]Training:  95%|█████████▌| 449/471 [20:19<00:46,  2.11s/it]Training:  96%|█████████▌| 450/471 [20:28<01:05,  3.12s/it]Training:  96%|█████████▌| 453/471 [20:30<00:37,  2.10s/it]Training:  96%|█████████▋| 454/471 [20:39<00:54,  3.21s/it]Training:  97%|█████████▋| 457/471 [20:41<00:30,  2.19s/it]Training:  97%|█████████▋| 458/471 [20:49<00:42,  3.25s/it]Training:  98%|█████████▊| 461/471 [20:52<00:22,  2.26s/it]Training:  98%|█████████▊| 462/471 [21:01<00:29,  3.30s/it]Training:  99%|█████████▊| 465/471 [21:03<00:13,  2.27s/it]Training:  99%|█████████▉| 466/471 [21:10<00:14,  3.00s/it]Training: 100%|█████████▉| 469/471 [21:12<00:04,  2.05s/it]Training: 100%|█████████▉| 470/471 [21:17<00:02,  2.57s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Training: 100%|██████████| 471/471 [21:17<00:00,  2.71s/it]
Evaluating:   0%|          | 0/118 [00:00<?, ?it/s]Evaluating:   1%|          | 1/118 [00:10<20:51, 10.70s/it]Evaluating:   3%|▎         | 3/118 [00:10<05:30,  2.88s/it]Evaluating:   4%|▍         | 5/118 [00:22<08:08,  4.32s/it]Evaluating:   6%|▌         | 7/118 [00:22<04:43,  2.55s/it]Evaluating:   8%|▊         | 9/118 [00:33<06:35,  3.63s/it]Evaluating:   9%|▉         | 11/118 [00:33<04:20,  2.44s/it]Evaluating:  11%|█         | 13/118 [00:44<05:52,  3.36s/it]Evaluating:  12%|█▏        | 14/118 [00:44<04:45,  2.74s/it]Evaluating:  13%|█▎        | 15/118 [00:44<03:49,  2.23s/it]Evaluating:  14%|█▍        | 17/118 [00:54<05:34,  3.31s/it]Evaluating:  15%|█▌        | 18/118 [00:55<04:32,  2.72s/it]Evaluating:  16%|█▌        | 19/118 [00:55<03:30,  2.13s/it]Evaluating:  18%|█▊        | 21/118 [01:06<05:24,  3.35s/it]Evaluating:  19%|█▊        | 22/118 [01:06<04:23,  2.74s/it]Evaluating:  19%|█▉        | 23/118 [01:07<03:28,  2.20s/it]Evaluating:  21%|██        | 25/118 [01:17<05:13,  3.37s/it]Evaluating:  22%|██▏       | 26/118 [01:17<04:11,  2.74s/it]Evaluating:  23%|██▎       | 27/118 [01:18<03:24,  2.25s/it]Evaluating:  25%|██▍       | 29/118 [01:28<05:07,  3.46s/it]Evaluating:  25%|██▌       | 30/118 [01:30<04:20,  2.97s/it]Evaluating:  28%|██▊       | 33/118 [01:39<04:18,  3.05s/it]Evaluating:  29%|██▉       | 34/118 [01:40<03:44,  2.67s/it]Evaluating:  30%|██▉       | 35/118 [01:40<02:56,  2.13s/it]Evaluating:  31%|███▏      | 37/118 [01:50<04:15,  3.15s/it]Evaluating:  32%|███▏      | 38/118 [01:51<03:31,  2.64s/it]Evaluating:  33%|███▎      | 39/118 [01:51<02:48,  2.13s/it]Evaluating:  35%|███▍      | 41/118 [02:01<04:01,  3.14s/it]Evaluating:  36%|███▌      | 42/118 [02:02<03:21,  2.66s/it]Evaluating:  36%|███▋      | 43/118 [02:02<02:38,  2.12s/it]Evaluating:  38%|███▊      | 45/118 [02:11<03:51,  3.17s/it]Evaluating:  39%|███▉      | 46/118 [02:12<03:14,  2.70s/it]Evaluating:  41%|████      | 48/118 [02:13<01:56,  1.66s/it]Evaluating:  42%|████▏     | 49/118 [02:22<03:49,  3.33s/it]Evaluating:  42%|████▏     | 50/118 [02:23<03:06,  2.74s/it]Evaluating:  43%|████▎     | 51/118 [02:23<02:20,  2.10s/it]Evaluating:  45%|████▍     | 53/118 [02:33<03:33,  3.29s/it]Evaluating:  46%|████▌     | 54/118 [02:33<02:50,  2.66s/it]Evaluating:  47%|████▋     | 55/118 [02:34<02:10,  2.07s/it]Evaluating:  48%|████▊     | 57/118 [02:43<03:17,  3.24s/it]Evaluating:  49%|████▉     | 58/118 [02:44<02:36,  2.62s/it]Evaluating:  50%|█████     | 59/118 [02:45<02:06,  2.14s/it]Evaluating:  52%|█████▏    | 61/118 [02:55<03:13,  3.39s/it]Evaluating:  53%|█████▎    | 62/118 [02:55<02:28,  2.66s/it]Evaluating:  53%|█████▎    | 63/118 [02:56<02:00,  2.19s/it]Evaluating:  55%|█████▌    | 65/118 [03:06<03:03,  3.47s/it]Evaluating:  56%|█████▌    | 66/118 [03:07<02:23,  2.76s/it]Evaluating:  57%|█████▋    | 67/118 [03:07<01:53,  2.23s/it]Evaluating:  58%|█████▊    | 68/118 [03:07<01:24,  1.69s/it]Evaluating:  58%|█████▊    | 69/118 [03:19<03:29,  4.28s/it]Evaluating:  62%|██████▏   | 73/118 [03:30<02:29,  3.31s/it]Evaluating:  65%|██████▌   | 77/118 [03:41<02:06,  3.07s/it]Evaluating:  69%|██████▊   | 81/118 [03:52<01:50,  2.98s/it]Evaluating:  72%|███████▏  | 85/118 [04:01<01:27,  2.67s/it]Evaluating:  75%|███████▌  | 89/118 [04:09<01:11,  2.46s/it]Evaluating:  79%|███████▉  | 93/118 [04:18<00:59,  2.37s/it]Evaluating:  82%|████████▏ | 97/118 [04:27<00:50,  2.39s/it]Evaluating:  86%|████████▌ | 101/118 [04:38<00:41,  2.46s/it]Evaluating:  89%|████████▉ | 105/118 [04:47<00:31,  2.46s/it]Evaluating:  92%|█████████▏| 109/118 [04:58<00:22,  2.49s/it]Evaluating:  96%|█████████▌| 113/118 [05:08<00:12,  2.49s/it]Evaluating:  99%|█████████▉| 117/118 [05:16<00:02,  2.37s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Evaluating: 100%|██████████| 118/118 [05:16<00:00,  2.68s/it]
/home2/s439765/.conda/envs/yolov8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training:   0%|          | 0/471 [00:00<?, ?it/s]Training:   0%|          | 1/471 [00:10<1:25:18, 10.89s/it]Training:   1%|          | 5/471 [00:21<29:25,  3.79s/it]  Training:   1%|▏         | 7/471 [00:21<18:24,  2.38s/it]Training:   2%|▏         | 9/471 [00:30<25:00,  3.25s/it]Training:   2%|▏         | 11/471 [00:31<16:54,  2.20s/it]Training:   3%|▎         | 13/471 [00:41<23:31,  3.08s/it]Training:   3%|▎         | 15/471 [00:41<16:35,  2.18s/it]Training:   4%|▎         | 17/471 [00:51<23:29,  3.10s/it]Training:   4%|▍         | 18/471 [00:52<19:57,  2.64s/it]Training:   4%|▍         | 21/471 [01:02<21:59,  2.93s/it]Training:   5%|▍         | 22/471 [01:02<18:45,  2.51s/it]Training:   5%|▌         | 25/471 [01:12<21:24,  2.88s/it]Training:   6%|▌         | 26/471 [01:13<18:11,  2.45s/it]Training:   6%|▌         | 29/471 [01:23<21:22,  2.90s/it]Training:   6%|▋         | 30/471 [01:23<17:57,  2.44s/it]Training:   7%|▋         | 33/471 [01:35<21:55,  3.00s/it]Training:   8%|▊         | 37/471 [01:46<20:59,  2.90s/it]Training:   9%|▊         | 41/471 [01:57<20:12,  2.82s/it]Training:   9%|▉         | 43/471 [01:57<15:58,  2.24s/it]Training:  10%|▉         | 45/471 [02:08<21:10,  2.98s/it]Training:  10%|▉         | 47/471 [02:08<16:10,  2.29s/it]Training:  10%|█         | 49/471 [02:19<21:31,  3.06s/it]Training:  11%|█         | 51/471 [02:20<16:35,  2.37s/it]Training:  11%|█▏        | 53/471 [02:30<22:16,  3.20s/it]Training:  12%|█▏        | 55/471 [02:31<16:46,  2.42s/it]Training:  12%|█▏        | 57/471 [02:41<21:49,  3.16s/it]Training:  13%|█▎        | 59/471 [02:42<16:31,  2.41s/it]Training:  13%|█▎        | 61/471 [02:52<21:31,  3.15s/it]Training:  13%|█▎        | 63/471 [02:54<16:46,  2.47s/it]Training:  14%|█▍        | 65/471 [03:03<20:34,  3.04s/it]Training:  14%|█▍        | 67/471 [03:04<16:09,  2.40s/it]Training:  15%|█▍        | 69/471 [03:13<20:00,  2.99s/it]Training:  15%|█▌        | 71/471 [03:15<15:24,  2.31s/it]Training:  15%|█▌        | 73/471 [03:25<20:43,  3.12s/it]Training:  16%|█▌        | 75/471 [03:26<15:47,  2.39s/it]Training:  16%|█▋        | 77/471 [03:36<20:29,  3.12s/it]Training:  17%|█▋        | 79/471 [03:37<15:36,  2.39s/it]Training:  17%|█▋        | 81/471 [03:47<20:04,  3.09s/it]Training:  17%|█▋        | 82/471 [03:47<16:49,  2.59s/it]Training:  18%|█▊        | 83/471 [03:48<14:36,  2.26s/it]Training:  18%|█▊        | 85/471 [03:58<21:01,  3.27s/it]Training:  18%|█▊        | 86/471 [03:58<17:23,  2.71s/it]Training:  18%|█▊        | 87/471 [04:00<16:08,  2.52s/it]Training:  19%|█▉        | 89/471 [04:09<20:28,  3.22s/it]Training:  19%|█▉        | 90/471 [04:10<17:00,  2.68s/it]Training:  19%|█▉        | 91/471 [04:11<15:44,  2.49s/it]Training:  20%|█▉        | 93/471 [04:20<19:50,  3.15s/it]Training:  20%|█▉        | 94/471 [04:21<17:24,  2.77s/it]Training:  20%|██        | 95/471 [04:22<15:08,  2.42s/it]Training:  21%|██        | 97/471 [04:30<18:58,  3.04s/it]Training:  21%|██        | 98/471 [04:32<16:47,  2.70s/it]Training:  21%|██        | 99/471 [04:33<14:19,  2.31s/it]Training:  21%|██▏       | 101/471 [04:41<18:32,  3.01s/it]Training:  22%|██▏       | 102/471 [04:43<16:51,  2.74s/it]Training:  22%|██▏       | 103/471 [04:44<14:17,  2.33s/it]Training:  22%|██▏       | 105/471 [04:52<18:18,  3.00s/it]Training:  23%|██▎       | 106/471 [04:54<16:46,  2.76s/it]Training:  23%|██▎       | 107/471 [04:55<14:09,  2.33s/it]Training:  23%|██▎       | 109/471 [05:02<17:40,  2.93s/it]Training:  23%|██▎       | 110/471 [05:04<16:03,  2.67s/it]Training:  24%|██▎       | 111/471 [05:05<14:01,  2.34s/it]Training:  24%|██▍       | 113/471 [05:13<17:57,  3.01s/it]Training:  24%|██▍       | 114/471 [05:15<16:13,  2.73s/it]Training:  24%|██▍       | 115/471 [05:16<13:49,  2.33s/it]Training:  25%|██▍       | 117/471 [05:24<17:43,  3.00s/it]Training:  25%|██▌       | 118/471 [05:26<15:57,  2.71s/it]Training:  25%|██▌       | 119/471 [05:27<13:39,  2.33s/it]Training:  26%|██▌       | 121/471 [05:35<17:37,  3.02s/it]Training:  26%|██▌       | 122/471 [05:37<15:56,  2.74s/it]Training:  26%|██▌       | 123/471 [05:38<13:43,  2.37s/it]Training:  27%|██▋       | 125/471 [05:46<17:56,  3.11s/it]Training:  27%|██▋       | 126/471 [05:48<15:25,  2.68s/it]Training:  27%|██▋       | 127/471 [05:49<13:19,  2.33s/it]Training:  27%|██▋       | 129/471 [05:57<17:43,  3.11s/it]Training:  28%|██▊       | 130/471 [05:59<15:42,  2.76s/it]Training:  28%|██▊       | 131/471 [06:00<12:51,  2.27s/it]Training:  28%|██▊       | 133/471 [06:09<18:04,  3.21s/it]Training:  28%|██▊       | 134/471 [06:10<16:02,  2.86s/it]Training:  29%|██▊       | 135/471 [06:11<13:26,  2.40s/it]Training:  29%|██▉       | 137/471 [06:20<18:03,  3.24s/it]Training:  29%|██▉       | 138/471 [06:22<15:32,  2.80s/it]Training:  30%|██▉       | 139/471 [06:23<13:06,  2.37s/it]Training:  30%|██▉       | 141/471 [06:31<17:06,  3.11s/it]Training:  30%|███       | 142/471 [06:33<15:06,  2.75s/it]Training:  30%|███       | 143/471 [06:34<13:23,  2.45s/it]Training:  31%|███       | 145/471 [06:42<16:19,  3.00s/it]Training:  31%|███       | 146/471 [06:43<14:35,  2.69s/it]Training:  31%|███       | 147/471 [06:45<13:22,  2.48s/it]Training:  32%|███▏      | 149/471 [06:52<15:55,  2.97s/it]Training:  32%|███▏      | 150/471 [06:54<14:32,  2.72s/it]Training:  32%|███▏      | 151/471 [06:56<13:19,  2.50s/it]Training:  32%|███▏      | 153/471 [07:03<15:25,  2.91s/it]Training:  33%|███▎      | 154/471 [07:05<14:22,  2.72s/it]Training:  33%|███▎      | 155/471 [07:07<12:57,  2.46s/it]Training:  33%|███▎      | 157/471 [07:14<15:17,  2.92s/it]Training:  34%|███▎      | 158/471 [07:16<14:01,  2.69s/it]Training:  34%|███▍      | 159/471 [07:18<12:54,  2.48s/it]Training:  34%|███▍      | 161/471 [07:25<15:01,  2.91s/it]Training:  34%|███▍      | 162/471 [07:27<13:47,  2.68s/it]Training:  35%|███▍      | 163/471 [07:29<12:42,  2.47s/it]Training:  35%|███▌      | 165/471 [07:36<15:17,  3.00s/it]Training:  35%|███▌      | 166/471 [07:37<13:21,  2.63s/it]Training:  35%|███▌      | 167/471 [07:39<12:13,  2.41s/it]Training:  36%|███▌      | 169/471 [07:47<14:50,  2.95s/it]Training:  36%|███▌      | 170/471 [07:48<13:16,  2.65s/it]Training:  36%|███▋      | 171/471 [07:50<12:01,  2.41s/it]Training:  37%|███▋      | 173/471 [07:57<14:34,  2.93s/it]Training:  37%|███▋      | 174/471 [07:59<13:14,  2.68s/it]Training:  37%|███▋      | 175/471 [08:01<12:01,  2.44s/it]Training:  38%|███▊      | 177/471 [08:06<12:38,  2.58s/it]Training:  38%|███▊      | 178/471 [08:08<11:17,  2.31s/it]Training:  38%|███▊      | 179/471 [08:09<09:40,  1.99s/it]Training:  38%|███▊      | 181/471 [08:15<11:33,  2.39s/it]Training:  39%|███▊      | 182/471 [08:16<10:36,  2.20s/it]Training:  39%|███▉      | 183/471 [08:17<09:04,  1.89s/it]Training:  39%|███▉      | 185/471 [08:24<11:38,  2.44s/it]Training:  39%|███▉      | 186/471 [08:25<10:47,  2.27s/it]Training:  40%|███▉      | 187/471 [08:26<08:55,  1.89s/it]Training:  40%|████      | 189/471 [08:33<12:17,  2.62s/it]Training:  40%|████      | 190/471 [08:34<10:36,  2.27s/it]Training:  41%|████      | 191/471 [08:35<08:59,  1.93s/it]Training:  41%|████      | 193/471 [08:43<12:15,  2.65s/it]Training:  41%|████      | 194/471 [08:44<10:33,  2.29s/it]Training:  41%|████▏     | 195/471 [08:45<09:29,  2.06s/it]Training:  42%|████▏     | 197/471 [08:53<12:52,  2.82s/it]Training:  42%|████▏     | 198/471 [08:54<10:59,  2.42s/it]Training:  42%|████▏     | 199/471 [08:55<09:19,  2.06s/it]Training:  43%|████▎     | 201/471 [09:03<12:44,  2.83s/it]Training:  43%|████▎     | 202/471 [09:04<11:01,  2.46s/it]Training:  43%|████▎     | 203/471 [09:05<09:22,  2.10s/it]Training:  44%|████▎     | 205/471 [09:13<12:54,  2.91s/it]Training:  44%|████▎     | 206/471 [09:14<11:10,  2.53s/it]Training:  44%|████▍     | 207/471 [09:15<09:35,  2.18s/it]Training:  44%|████▍     | 209/471 [09:23<12:07,  2.78s/it]Training:  45%|████▍     | 210/471 [09:24<10:35,  2.43s/it]Training:  45%|████▍     | 211/471 [09:25<08:51,  2.05s/it]Training:  45%|████▌     | 213/471 [09:32<11:46,  2.74s/it]Training:  45%|████▌     | 214/471 [09:33<10:18,  2.41s/it]Training:  46%|████▌     | 215/471 [09:34<08:23,  1.97s/it]Training:  46%|████▌     | 217/471 [09:42<11:40,  2.76s/it]Training:  46%|████▋     | 218/471 [09:44<10:33,  2.50s/it]Training:  46%|████▋     | 219/471 [09:44<08:42,  2.07s/it]Training:  47%|████▋     | 221/471 [09:52<11:22,  2.73s/it]Training:  47%|████▋     | 222/471 [09:53<09:44,  2.35s/it]Training:  47%|████▋     | 223/471 [09:54<08:41,  2.10s/it]Training:  48%|████▊     | 225/471 [10:01<10:57,  2.67s/it]Training:  48%|████▊     | 226/471 [10:02<09:11,  2.25s/it]Training:  48%|████▊     | 227/471 [10:03<08:09,  2.01s/it]Training:  49%|████▊     | 229/471 [10:10<10:49,  2.69s/it]Training:  49%|████▉     | 230/471 [10:11<09:04,  2.26s/it]Training:  49%|████▉     | 231/471 [10:12<08:04,  2.02s/it]Training:  49%|████▉     | 233/471 [10:21<11:29,  2.90s/it]Training:  50%|████▉     | 234/471 [10:21<09:19,  2.36s/it]Training:  50%|████▉     | 235/471 [10:23<08:17,  2.11s/it]Training:  50%|█████     | 237/471 [10:31<11:26,  2.93s/it]Training:  51%|█████     | 238/471 [10:32<09:33,  2.46s/it]Training:  51%|█████     | 239/471 [10:33<08:20,  2.16s/it]Training:  51%|█████     | 241/471 [10:42<11:48,  3.08s/it]Training:  51%|█████▏    | 242/471 [10:42<09:46,  2.56s/it]Training:  52%|█████▏    | 243/471 [10:43<08:10,  2.15s/it]Training:  52%|█████▏    | 245/471 [10:53<12:09,  3.23s/it]Training:  52%|█████▏    | 246/471 [10:54<10:16,  2.74s/it]Training:  52%|█████▏    | 247/471 [10:54<08:10,  2.19s/it]Training:  53%|█████▎    | 249/471 [11:04<12:10,  3.29s/it]Training:  53%|█████▎    | 250/471 [11:05<09:56,  2.70s/it]Training:  53%|█████▎    | 251/471 [11:05<07:46,  2.12s/it]Training:  54%|█████▎    | 253/471 [11:15<12:01,  3.31s/it]Training:  54%|█████▍    | 254/471 [11:16<09:52,  2.73s/it]Training:  54%|█████▍    | 255/471 [11:16<07:43,  2.15s/it]Training:  55%|█████▍    | 257/471 [11:26<11:38,  3.26s/it]Training:  55%|█████▍    | 258/471 [11:27<09:30,  2.68s/it]Training:  55%|█████▍    | 259/471 [11:27<07:29,  2.12s/it]Training:  55%|█████▌    | 261/471 [11:37<11:16,  3.22s/it]Training:  56%|█████▌    | 262/471 [11:38<09:17,  2.67s/it]Training:  56%|█████▌    | 263/471 [11:38<07:29,  2.16s/it]Training:  56%|█████▋    | 265/471 [11:47<10:52,  3.17s/it]Training:  56%|█████▋    | 266/471 [11:49<09:15,  2.71s/it]Training:  57%|█████▋    | 267/471 [11:49<07:22,  2.17s/it]Training:  57%|█████▋    | 269/471 [11:58<10:38,  3.16s/it]Training:  57%|█████▋    | 270/471 [11:59<09:05,  2.71s/it]Training:  58%|█████▊    | 271/471 [12:00<06:56,  2.08s/it]Training:  58%|█████▊    | 273/471 [12:08<10:01,  3.04s/it]Training:  58%|█████▊    | 274/471 [12:13<11:30,  3.51s/it]Training:  59%|█████▉    | 277/471 [12:19<08:42,  2.69s/it]Training:  59%|█████▉    | 278/471 [12:24<10:09,  3.16s/it]Training:  60%|█████▉    | 281/471 [12:29<07:56,  2.51s/it]Training:  60%|█████▉    | 282/471 [12:34<09:24,  2.98s/it]Training:  61%|██████    | 285/471 [12:40<07:39,  2.47s/it]Training:  61%|██████    | 286/471 [12:45<09:06,  2.96s/it]Training:  61%|██████▏   | 289/471 [12:50<07:20,  2.42s/it]Training:  62%|██████▏   | 290/471 [12:56<08:46,  2.91s/it]Training:  62%|██████▏   | 293/471 [13:01<07:12,  2.43s/it]Training:  62%|██████▏   | 294/471 [13:06<08:28,  2.87s/it]Training:  63%|██████▎   | 297/471 [13:11<07:01,  2.42s/it]Training:  63%|██████▎   | 298/471 [13:17<08:20,  2.90s/it]Training:  64%|██████▍   | 301/471 [13:22<06:58,  2.46s/it]Training:  64%|██████▍   | 302/471 [13:28<08:24,  2.98s/it]Training:  65%|██████▍   | 305/471 [13:34<07:08,  2.58s/it]Training:  65%|██████▍   | 306/471 [13:39<08:04,  2.93s/it]Training:  66%|██████▌   | 309/471 [13:45<06:56,  2.57s/it]Training:  66%|██████▌   | 310/471 [13:49<07:50,  2.92s/it]Training:  66%|██████▋   | 313/471 [13:55<06:41,  2.54s/it]Training:  67%|██████▋   | 314/471 [14:01<07:49,  2.99s/it]Training:  67%|██████▋   | 317/471 [14:07<06:36,  2.58s/it]Training:  68%|██████▊   | 318/471 [14:12<07:35,  2.97s/it]Training:  68%|██████▊   | 321/471 [14:17<06:17,  2.52s/it]Training:  68%|██████▊   | 322/471 [14:22<07:16,  2.93s/it]Training:  69%|██████▉   | 325/471 [14:28<06:02,  2.48s/it]Training:  69%|██████▉   | 326/471 [14:33<07:11,  2.98s/it]Training:  70%|██████▉   | 329/471 [14:39<05:53,  2.49s/it]Training:  70%|███████   | 330/471 [14:45<07:12,  3.06s/it]Training:  71%|███████   | 333/471 [14:49<05:33,  2.41s/it]Training:  71%|███████   | 334/471 [14:56<07:07,  3.12s/it]Training:  72%|███████▏  | 337/471 [15:00<05:27,  2.44s/it]Training:  72%|███████▏  | 338/471 [15:07<06:51,  3.10s/it]Training:  72%|███████▏  | 341/471 [15:12<05:22,  2.48s/it]Training:  73%|███████▎  | 342/471 [15:18<06:37,  3.08s/it]Training:  73%|███████▎  | 345/471 [15:23<05:13,  2.49s/it]Training:  73%|███████▎  | 346/471 [15:29<06:25,  3.08s/it]Training:  74%|███████▍  | 349/471 [15:33<04:58,  2.45s/it]Training:  74%|███████▍  | 350/471 [15:40<06:09,  3.05s/it]Training:  75%|███████▍  | 353/471 [15:44<04:46,  2.42s/it]Training:  75%|███████▌  | 354/471 [15:51<06:01,  3.09s/it]Training:  76%|███████▌  | 357/471 [15:54<04:28,  2.35s/it]Training:  76%|███████▌  | 358/471 [16:01<05:48,  3.09s/it]Training:  77%|███████▋  | 361/471 [16:06<04:23,  2.40s/it]Training:  77%|███████▋  | 362/471 [16:12<05:41,  3.13s/it]Training:  77%|███████▋  | 365/471 [16:16<04:11,  2.37s/it]Training:  78%|███████▊  | 366/471 [16:23<05:20,  3.05s/it]Training:  78%|███████▊  | 369/471 [16:27<04:07,  2.42s/it]Training:  79%|███████▊  | 370/471 [16:34<05:11,  3.08s/it]Training:  79%|███████▉  | 373/471 [16:38<03:54,  2.39s/it]Training:  79%|███████▉  | 374/471 [16:45<05:08,  3.18s/it]Training:  80%|████████  | 377/471 [16:49<03:47,  2.43s/it]Training:  80%|████████  | 378/471 [16:56<04:50,  3.12s/it]Training:  81%|████████  | 381/471 [17:00<03:33,  2.38s/it]Training:  81%|████████  | 382/471 [17:06<04:32,  3.06s/it]Training:  82%|████████▏ | 385/471 [17:11<03:28,  2.42s/it]Training:  82%|████████▏ | 386/471 [17:17<04:13,  2.99s/it]Training:  83%|████████▎ | 389/471 [17:22<03:16,  2.39s/it]Training:  83%|████████▎ | 390/471 [17:26<03:41,  2.73s/it]Training:  83%|████████▎ | 393/471 [17:30<02:42,  2.09s/it]Training:  84%|████████▎ | 394/471 [17:34<03:10,  2.47s/it]Training:  84%|████████▍ | 397/471 [17:38<02:24,  1.96s/it]Training:  85%|████████▍ | 398/471 [17:43<03:02,  2.50s/it]Training:  85%|████████▌ | 401/471 [17:46<02:16,  1.95s/it]Training:  85%|████████▌ | 402/471 [17:52<02:52,  2.50s/it]Training:  86%|████████▌ | 405/471 [17:56<02:20,  2.12s/it]Training:  86%|████████▌ | 406/471 [18:02<02:52,  2.65s/it]Training:  87%|████████▋ | 409/471 [18:06<02:14,  2.17s/it]Training:  87%|████████▋ | 410/471 [18:12<02:45,  2.71s/it]Training:  88%|████████▊ | 413/471 [18:16<02:08,  2.21s/it]Training:  88%|████████▊ | 414/471 [18:22<02:35,  2.73s/it]Training:  89%|████████▊ | 417/471 [18:26<01:59,  2.22s/it]Training:  89%|████████▊ | 418/471 [18:32<02:31,  2.86s/it]Training:  89%|████████▉ | 421/471 [18:36<01:53,  2.27s/it]Training:  90%|████████▉ | 422/471 [18:43<02:26,  3.00s/it]Training:  90%|█████████ | 425/471 [18:47<01:44,  2.27s/it]Training:  90%|█████████ | 426/471 [18:53<02:09,  2.88s/it]Training:  91%|█████████ | 429/471 [18:57<01:33,  2.22s/it]Training:  91%|█████████▏| 430/471 [19:02<01:54,  2.78s/it]Training:  92%|█████████▏| 433/471 [19:06<01:23,  2.19s/it]Training:  92%|█████████▏| 434/471 [19:13<01:47,  2.90s/it]Training:  93%|█████████▎| 437/471 [19:17<01:18,  2.30s/it]Training:  93%|█████████▎| 438/471 [19:23<01:34,  2.85s/it]Training:  94%|█████████▎| 441/471 [19:28<01:10,  2.35s/it]Training:  94%|█████████▍| 442/471 [19:34<01:25,  2.95s/it]Training:  94%|█████████▍| 445/471 [19:39<01:02,  2.42s/it]Training:  95%|█████████▍| 446/471 [19:44<01:13,  2.93s/it]Training:  95%|█████████▌| 449/471 [19:49<00:52,  2.37s/it]Training:  96%|█████████▌| 450/471 [19:55<01:02,  2.97s/it]Training:  96%|█████████▌| 453/471 [20:00<00:42,  2.37s/it]Training:  96%|█████████▋| 454/471 [20:06<00:51,  3.05s/it]Training:  97%|█████████▋| 457/471 [20:11<00:34,  2.49s/it]Training:  97%|█████████▋| 458/471 [20:17<00:38,  3.00s/it]Training:  98%|█████████▊| 461/471 [20:22<00:24,  2.49s/it]Training:  98%|█████████▊| 462/471 [20:27<00:26,  2.96s/it]Training:  99%|█████████▊| 465/471 [20:33<00:14,  2.46s/it]Training:  99%|█████████▉| 466/471 [20:37<00:14,  2.81s/it]Training: 100%|█████████▉| 469/471 [20:42<00:04,  2.26s/it]Training: 100%|█████████▉| 470/471 [20:45<00:02,  2.40s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Training: 100%|██████████| 471/471 [20:45<00:00,  2.64s/it]
Evaluating:   0%|          | 0/118 [00:00<?, ?it/s]Evaluating:   1%|          | 1/118 [00:11<22:30, 11.55s/it]Evaluating:   4%|▍         | 5/118 [00:21<07:22,  3.91s/it]Evaluating:   5%|▌         | 6/118 [00:22<05:44,  3.07s/it]Evaluating:   8%|▊         | 9/118 [00:32<05:51,  3.22s/it]Evaluating:   8%|▊         | 10/118 [00:32<04:48,  2.67s/it]Evaluating:  10%|█         | 12/118 [00:33<03:17,  1.86s/it]Evaluating:  11%|█         | 13/118 [00:42<05:48,  3.32s/it]Evaluating:  12%|█▏        | 14/118 [00:42<04:31,  2.61s/it]Evaluating:  14%|█▎        | 16/118 [00:44<03:14,  1.91s/it]Evaluating:  14%|█▍        | 17/118 [00:53<05:51,  3.48s/it]Evaluating:  17%|█▋        | 20/118 [00:54<03:20,  2.04s/it]Evaluating:  18%|█▊        | 21/118 [01:04<05:34,  3.44s/it]Evaluating:  20%|██        | 24/118 [01:06<03:21,  2.15s/it]Evaluating:  21%|██        | 25/118 [01:15<05:15,  3.39s/it]Evaluating:  22%|██▏       | 26/118 [01:15<04:13,  2.75s/it]Evaluating:  24%|██▎       | 28/118 [01:17<03:03,  2.03s/it]Evaluating:  25%|██▍       | 29/118 [01:26<05:10,  3.48s/it]Evaluating:  25%|██▌       | 30/118 [01:27<04:23,  2.99s/it]Evaluating:  27%|██▋       | 32/118 [01:27<02:39,  1.86s/it]Evaluating:  28%|██▊       | 33/118 [01:37<05:01,  3.55s/it]Evaluating:  29%|██▉       | 34/118 [01:38<04:04,  2.91s/it]Evaluating:  31%|███       | 36/118 [01:38<02:32,  1.86s/it]Evaluating:  31%|███▏      | 37/118 [01:48<04:46,  3.54s/it]Evaluating:  32%|███▏      | 38/118 [01:49<03:55,  2.94s/it]Evaluating:  34%|███▍      | 40/118 [01:49<02:24,  1.85s/it]Evaluating:  35%|███▍      | 41/118 [01:59<04:34,  3.57s/it]Evaluating:  36%|███▌      | 42/118 [02:00<03:46,  2.98s/it]Evaluating:  37%|███▋      | 44/118 [02:00<02:15,  1.83s/it]Evaluating:  38%|███▊      | 45/118 [02:10<04:31,  3.72s/it]Evaluating:  39%|███▉      | 46/118 [02:11<03:32,  2.94s/it]Evaluating:  41%|████      | 48/118 [02:11<02:06,  1.81s/it]Evaluating:  42%|████▏     | 49/118 [02:21<04:04,  3.55s/it]Evaluating:  42%|████▏     | 50/118 [02:21<03:12,  2.83s/it]Evaluating:  44%|████▍     | 52/118 [02:21<01:51,  1.69s/it]Evaluating:  45%|████▍     | 53/118 [02:31<03:52,  3.58s/it]Evaluating:  46%|████▌     | 54/118 [02:32<03:04,  2.88s/it]Evaluating:  48%|████▊     | 57/118 [02:42<03:12,  3.16s/it]Evaluating:  49%|████▉     | 58/118 [02:43<02:37,  2.62s/it]Evaluating:  51%|█████     | 60/118 [02:43<01:41,  1.76s/it]Evaluating:  52%|█████▏    | 61/118 [02:53<03:18,  3.48s/it]Evaluating:  53%|█████▎    | 62/118 [02:54<02:38,  2.83s/it]Evaluating:  54%|█████▍    | 64/118 [02:54<01:36,  1.79s/it]Evaluating:  55%|█████▌    | 65/118 [03:05<03:13,  3.64s/it]Evaluating:  56%|█████▌    | 66/118 [03:06<02:34,  2.97s/it]Evaluating:  58%|█████▊    | 68/118 [03:06<01:30,  1.81s/it]Evaluating:  58%|█████▊    | 69/118 [03:15<02:53,  3.53s/it]Evaluating:  59%|█████▉    | 70/118 [03:16<02:15,  2.83s/it]Evaluating:  61%|██████    | 72/118 [03:16<01:20,  1.75s/it]Evaluating:  62%|██████▏   | 73/118 [03:26<02:37,  3.50s/it]Evaluating:  63%|██████▎   | 74/118 [03:26<02:04,  2.82s/it]Evaluating:  64%|██████▍   | 76/118 [03:27<01:12,  1.72s/it]Evaluating:  65%|██████▌   | 77/118 [03:37<02:25,  3.56s/it]Evaluating:  66%|██████▌   | 78/118 [03:37<01:53,  2.83s/it]Evaluating:  68%|██████▊   | 80/118 [03:38<01:06,  1.76s/it]Evaluating:  69%|██████▊   | 81/118 [03:47<02:12,  3.59s/it]Evaluating:  69%|██████▉   | 82/118 [03:48<01:42,  2.85s/it]Evaluating:  71%|███████   | 84/118 [03:49<01:02,  1.83s/it]Evaluating:  72%|███████▏  | 85/118 [03:58<01:59,  3.61s/it]Evaluating:  73%|███████▎  | 86/118 [03:59<01:30,  2.83s/it]Evaluating:  75%|███████▍  | 88/118 [04:00<00:56,  1.89s/it]Evaluating:  75%|███████▌  | 89/118 [04:09<01:44,  3.59s/it]Evaluating:  76%|███████▋  | 90/118 [04:10<01:19,  2.82s/it]Evaluating:  78%|███████▊  | 92/118 [04:12<00:53,  2.05s/it]Evaluating:  79%|███████▉  | 93/118 [04:21<01:31,  3.64s/it]Evaluating:  80%|███████▉  | 94/118 [04:21<01:06,  2.78s/it]Evaluating:  81%|████████▏ | 96/118 [04:22<00:43,  1.97s/it]Evaluating:  82%|████████▏ | 97/118 [04:32<01:16,  3.67s/it]Evaluating:  85%|████████▍ | 100/118 [04:33<00:37,  2.09s/it]Evaluating:  86%|████████▌ | 101/118 [04:43<00:59,  3.51s/it]Evaluating:  88%|████████▊ | 104/118 [04:44<00:29,  2.14s/it]Evaluating:  89%|████████▉ | 105/118 [04:54<00:45,  3.47s/it]Evaluating:  92%|█████████▏| 108/118 [04:55<00:21,  2.13s/it]Evaluating:  92%|█████████▏| 109/118 [05:05<00:30,  3.42s/it]Evaluating:  94%|█████████▍| 111/118 [05:05<00:16,  2.32s/it]Evaluating:  95%|█████████▍| 112/118 [05:06<00:12,  2.10s/it]Evaluating:  96%|█████████▌| 113/118 [05:15<00:18,  3.68s/it]Evaluating:  97%|█████████▋| 114/118 [05:16<00:11,  2.89s/it]Evaluating:  98%|█████████▊| 116/118 [05:16<00:03,  1.86s/it]Evaluating:  99%|█████████▉| 117/118 [05:23<00:02,  2.83s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Evaluating: 100%|██████████| 118/118 [05:23<00:00,  2.74s/it]
/home2/s439765/.conda/envs/yolov8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Training:   0%|          | 0/471 [00:00<?, ?it/s]Training:   0%|          | 1/471 [00:08<1:05:16,  8.33s/it]Training:   0%|          | 2/471 [00:08<29:28,  3.77s/it]  Training:   1%|          | 5/471 [00:16<22:31,  2.90s/it]Training:   1%|▏         | 6/471 [00:16<17:16,  2.23s/it]Training:   2%|▏         | 9/471 [00:24<18:54,  2.46s/it]Training:   2%|▏         | 10/471 [00:25<15:32,  2.02s/it]Training:   3%|▎         | 13/471 [00:33<18:29,  2.42s/it]Training:   3%|▎         | 14/471 [00:33<15:23,  2.02s/it]Training:   3%|▎         | 16/471 [00:34<10:21,  1.37s/it]Training:   4%|▎         | 17/471 [00:42<20:17,  2.68s/it]Training:   4%|▍         | 18/471 [00:42<16:09,  2.14s/it]Training:   4%|▍         | 20/471 [00:43<11:04,  1.47s/it]Training:   4%|▍         | 21/471 [00:51<21:50,  2.91s/it]Training:   5%|▍         | 22/471 [00:51<17:04,  2.28s/it]Training:   5%|▌         | 24/471 [00:52<11:04,  1.49s/it]Training:   5%|▌         | 25/471 [00:59<21:09,  2.85s/it]Training:   6%|▌         | 28/471 [01:00<11:48,  1.60s/it]Training:   6%|▌         | 29/471 [01:08<20:54,  2.84s/it]Training:   7%|▋         | 32/471 [01:10<13:00,  1.78s/it]Training:   7%|▋         | 33/471 [01:18<21:33,  2.95s/it]Training:   8%|▊         | 36/471 [01:19<13:08,  1.81s/it]Training:   8%|▊         | 37/471 [01:28<21:25,  2.96s/it]Training:   8%|▊         | 40/471 [01:29<14:01,  1.95s/it]Training:   9%|▊         | 41/471 [01:38<21:20,  2.98s/it]Training:   9%|▉         | 44/471 [01:40<14:35,  2.05s/it]Training:  10%|▉         | 45/471 [01:47<20:47,  2.93s/it]Training:  10%|█         | 48/471 [01:49<14:11,  2.01s/it]Training:  10%|█         | 49/471 [01:57<20:51,  2.97s/it]Training:  11%|█         | 52/471 [01:59<14:26,  2.07s/it]Training:  11%|█▏        | 53/471 [02:07<21:06,  3.03s/it]Training:  12%|█▏        | 56/471 [02:10<14:38,  2.12s/it]Training:  12%|█▏        | 57/471 [02:18<21:15,  3.08s/it]Training:  13%|█▎        | 60/471 [02:20<14:47,  2.16s/it]Training:  13%|█▎        | 61/471 [02:29<21:35,  3.16s/it]Training:  14%|█▎        | 64/471 [02:31<14:46,  2.18s/it]Training:  14%|█▍        | 65/471 [02:39<21:06,  3.12s/it]Training:  14%|█▍        | 68/471 [02:42<14:44,  2.20s/it]Training:  15%|█▍        | 69/471 [02:49<20:51,  3.11s/it]Training:  15%|█▌        | 72/471 [02:51<14:01,  2.11s/it]Training:  15%|█▌        | 73/471 [03:00<20:49,  3.14s/it]Training:  16%|█▌        | 76/471 [03:02<13:55,  2.12s/it]Training:  16%|█▋        | 77/471 [03:10<20:01,  3.05s/it]Training:  17%|█▋        | 80/471 [03:12<13:39,  2.09s/it]Training:  17%|█▋        | 81/471 [03:20<19:40,  3.03s/it]Training:  18%|█▊        | 84/471 [03:22<13:37,  2.11s/it]Training:  18%|█▊        | 85/471 [03:29<19:19,  3.00s/it]Training:  19%|█▊        | 88/471 [03:32<13:23,  2.10s/it]Training:  19%|█▉        | 89/471 [03:40<19:26,  3.05s/it]Training:  20%|█▉        | 92/471 [03:42<13:19,  2.11s/it]Training:  20%|█▉        | 93/471 [03:50<19:31,  3.10s/it]Training:  20%|██        | 96/471 [03:52<12:53,  2.06s/it]Training:  21%|██        | 97/471 [04:00<19:12,  3.08s/it]Training:  21%|██        | 100/471 [04:02<12:54,  2.09s/it]Training:  21%|██▏       | 101/471 [04:11<19:04,  3.09s/it]Training:  22%|██▏       | 104/471 [04:13<12:59,  2.12s/it]Training:  22%|██▏       | 105/471 [04:21<18:43,  3.07s/it]Training:  23%|██▎       | 108/471 [04:23<12:59,  2.15s/it]Training:  23%|██▎       | 109/471 [04:31<18:11,  3.02s/it]Training:  23%|██▎       | 110/471 [04:32<15:55,  2.65s/it]Training:  24%|██▍       | 112/471 [04:33<11:52,  1.98s/it]Training:  24%|██▍       | 113/471 [04:41<18:46,  3.15s/it]Training:  24%|██▍       | 114/471 [04:42<16:08,  2.71s/it]Training:  25%|██▍       | 116/471 [04:43<11:04,  1.87s/it]Training:  25%|██▍       | 117/471 [04:51<18:43,  3.17s/it]Training:  25%|██▌       | 118/471 [04:52<15:47,  2.68s/it]Training:  25%|██▌       | 120/471 [04:53<10:33,  1.80s/it]Training:  26%|██▌       | 121/471 [05:01<18:21,  3.15s/it]Training:  26%|██▌       | 122/471 [05:03<16:14,  2.79s/it]Training:  26%|██▋       | 124/471 [05:04<10:57,  1.89s/it]Training:  27%|██▋       | 125/471 [05:12<18:34,  3.22s/it]Training:  27%|██▋       | 126/471 [05:13<16:14,  2.82s/it]Training:  27%|██▋       | 128/471 [05:14<10:52,  1.90s/it]Training:  27%|██▋       | 129/471 [05:22<18:16,  3.21s/it]Training:  28%|██▊       | 130/471 [05:23<15:37,  2.75s/it]Training:  28%|██▊       | 132/471 [05:25<10:29,  1.86s/it]Training:  28%|██▊       | 133/471 [05:33<18:11,  3.23s/it]Training:  28%|██▊       | 134/471 [05:34<15:35,  2.77s/it]Training:  29%|██▉       | 136/471 [05:35<10:32,  1.89s/it]Training:  29%|██▉       | 137/471 [05:43<17:42,  3.18s/it]Training:  29%|██▉       | 138/471 [05:44<14:53,  2.68s/it]Training:  30%|██▉       | 140/471 [05:45<10:04,  1.82s/it]Training:  30%|██▉       | 141/471 [05:53<17:52,  3.25s/it]Training:  30%|███       | 142/471 [05:54<15:12,  2.77s/it]Training:  31%|███       | 144/471 [05:56<10:13,  1.88s/it]Training:  31%|███       | 145/471 [06:03<17:18,  3.19s/it]Training:  31%|███       | 146/471 [06:05<15:26,  2.85s/it]Training:  31%|███▏      | 148/471 [06:06<10:19,  1.92s/it]Training:  32%|███▏      | 149/471 [06:14<16:54,  3.15s/it]Training:  32%|███▏      | 150/471 [06:15<15:07,  2.83s/it]Training:  32%|███▏      | 152/471 [06:17<10:24,  1.96s/it]Training:  32%|███▏      | 153/471 [06:24<16:27,  3.11s/it]Training:  33%|███▎      | 154/471 [06:26<15:26,  2.92s/it]Training:  33%|███▎      | 156/471 [06:27<10:23,  1.98s/it]Training:  33%|███▎      | 157/471 [06:34<16:17,  3.11s/it]Training:  34%|███▎      | 158/471 [06:37<15:09,  2.91s/it]Training:  34%|███▍      | 160/471 [06:38<10:18,  1.99s/it]Training:  34%|███▍      | 161/471 [06:45<16:05,  3.12s/it]Training:  34%|███▍      | 162/471 [06:48<15:33,  3.02s/it]Training:  35%|███▍      | 164/471 [06:49<10:11,  1.99s/it]Training:  35%|███▌      | 165/471 [06:55<15:30,  3.04s/it]Training:  35%|███▌      | 166/471 [06:58<15:27,  3.04s/it]Training:  36%|███▌      | 168/471 [07:00<10:10,  2.01s/it]Training:  36%|███▌      | 169/471 [07:07<15:53,  3.16s/it]Training:  36%|███▌      | 170/471 [07:09<14:49,  2.96s/it]Training:  37%|███▋      | 172/471 [07:10<09:35,  1.92s/it]Training:  37%|███▋      | 173/471 [07:18<16:14,  3.27s/it]Training:  37%|███▋      | 174/471 [07:20<14:48,  2.99s/it]Training:  37%|███▋      | 176/471 [07:21<09:41,  1.97s/it]Training:  38%|███▊      | 177/471 [07:28<15:47,  3.22s/it]Training:  38%|███▊      | 178/471 [07:31<14:30,  2.97s/it]Training:  38%|███▊      | 180/471 [07:31<09:19,  1.92s/it]Training:  38%|███▊      | 181/471 [07:39<15:30,  3.21s/it]Training:  39%|███▊      | 182/471 [07:41<14:10,  2.94s/it]Training:  39%|███▉      | 184/471 [07:42<09:10,  1.92s/it]Training:  39%|███▉      | 185/471 [07:50<15:35,  3.27s/it]Training:  39%|███▉      | 186/471 [07:52<14:00,  2.95s/it]Training:  40%|███▉      | 188/471 [07:53<08:58,  1.90s/it]Training:  40%|████      | 189/471 [08:01<16:05,  3.42s/it]Training:  40%|████      | 190/471 [08:03<13:56,  2.98s/it]Training:  41%|████      | 192/471 [08:03<08:39,  1.86s/it]Training:  41%|████      | 193/471 [08:09<13:04,  2.82s/it]Training:  41%|████      | 194/471 [08:11<11:29,  2.49s/it]Training:  42%|████▏     | 196/471 [08:11<06:52,  1.50s/it]Training:  42%|████▏     | 197/471 [08:17<11:18,  2.48s/it]Training:  42%|████▏     | 198/471 [08:19<10:30,  2.31s/it]Training:  42%|████▏     | 200/471 [08:19<06:16,  1.39s/it]Training:  43%|████▎     | 201/471 [08:25<11:35,  2.58s/it]Training:  43%|████▎     | 202/471 [08:27<10:48,  2.41s/it]Training:  44%|████▎     | 205/471 [08:34<10:34,  2.38s/it]Training:  44%|████▎     | 206/471 [08:37<10:25,  2.36s/it]Training:  44%|████▍     | 209/471 [08:43<10:06,  2.32s/it]Training:  45%|████▍     | 210/471 [08:46<10:08,  2.33s/it]Training:  45%|████▌     | 213/471 [08:53<10:11,  2.37s/it]Training:  45%|████▌     | 214/471 [08:55<09:45,  2.28s/it]Training:  46%|████▌     | 217/471 [09:02<09:30,  2.25s/it]Training:  46%|████▋     | 218/471 [09:03<08:57,  2.13s/it]Training:  47%|████▋     | 220/471 [09:03<06:04,  1.45s/it]Training:  47%|████▋     | 221/471 [09:10<10:05,  2.42s/it]Training:  47%|████▋     | 222/471 [09:11<08:54,  2.15s/it]Training:  48%|████▊     | 225/471 [09:18<09:28,  2.31s/it]Training:  48%|████▊     | 226/471 [09:20<08:35,  2.11s/it]Training:  49%|████▊     | 229/471 [09:27<09:23,  2.33s/it]Training:  49%|████▉     | 230/471 [09:29<08:47,  2.19s/it]Training:  49%|████▉     | 233/471 [09:37<09:23,  2.37s/it]Training:  50%|████▉     | 234/471 [09:38<08:39,  2.19s/it]Training:  50%|█████     | 237/471 [09:46<09:23,  2.41s/it]Training:  51%|█████     | 238/471 [09:47<08:33,  2.20s/it]Training:  51%|█████     | 241/471 [09:57<09:48,  2.56s/it]Training:  51%|█████▏    | 242/471 [09:57<08:41,  2.28s/it]Training:  52%|█████▏    | 245/471 [10:06<09:41,  2.57s/it]Training:  52%|█████▏    | 246/471 [10:08<08:46,  2.34s/it]Training:  53%|█████▎    | 249/471 [10:16<09:33,  2.58s/it]Training:  53%|█████▎    | 250/471 [10:18<08:42,  2.37s/it]Training:  54%|█████▎    | 253/471 [10:26<09:12,  2.54s/it]Training:  54%|█████▍    | 254/471 [10:27<08:20,  2.31s/it]Training:  55%|█████▍    | 257/471 [10:35<08:45,  2.45s/it]Training:  55%|█████▍    | 258/471 [10:36<08:03,  2.27s/it]Training:  55%|█████▌    | 261/471 [10:45<08:59,  2.57s/it]Training:  56%|█████▌    | 262/471 [10:47<08:22,  2.41s/it]Training:  56%|█████▋    | 265/471 [10:56<09:07,  2.66s/it]Training:  56%|█████▋    | 266/471 [10:57<08:16,  2.42s/it]Training:  57%|█████▋    | 269/471 [11:07<09:10,  2.72s/it]Training:  57%|█████▋    | 270/471 [11:08<08:16,  2.47s/it]Training:  58%|█████▊    | 273/471 [11:17<09:06,  2.76s/it]Training:  58%|█████▊    | 274/471 [11:19<08:15,  2.52s/it]Training:  59%|█████▉    | 277/471 [11:28<08:58,  2.78s/it]Training:  59%|█████▉    | 278/471 [11:29<08:07,  2.53s/it]Training:  60%|█████▉    | 281/471 [11:39<08:43,  2.75s/it]Training:  60%|█████▉    | 282/471 [11:40<08:04,  2.56s/it]Training:  61%|██████    | 285/471 [11:49<08:29,  2.74s/it]Training:  61%|██████    | 286/471 [11:50<07:32,  2.45s/it]Training:  61%|██████▏   | 289/471 [12:00<08:19,  2.75s/it]Training:  62%|██████▏   | 290/471 [12:01<07:36,  2.52s/it]Training:  62%|██████▏   | 293/471 [12:10<08:09,  2.75s/it]Training:  62%|██████▏   | 294/471 [12:12<07:29,  2.54s/it]Training:  63%|██████▎   | 297/471 [12:21<08:02,  2.77s/it]Training:  63%|██████▎   | 298/471 [12:22<07:20,  2.55s/it]Training:  64%|██████▍   | 301/471 [12:32<07:49,  2.76s/it]Training:  64%|██████▍   | 302/471 [12:33<07:09,  2.54s/it]Training:  65%|██████▍   | 305/471 [12:42<07:40,  2.77s/it]Training:  65%|██████▍   | 306/471 [12:44<06:56,  2.52s/it]Training:  66%|██████▌   | 309/471 [12:53<07:26,  2.75s/it]Training:  66%|██████▌   | 310/471 [12:54<06:44,  2.51s/it]Training:  66%|██████▋   | 313/471 [13:03<07:15,  2.76s/it]Training:  67%|██████▋   | 314/471 [13:04<06:28,  2.48s/it]Training:  67%|██████▋   | 317/471 [13:14<07:10,  2.80s/it]Training:  68%|██████▊   | 318/471 [13:15<06:18,  2.47s/it]Training:  68%|██████▊   | 321/471 [13:25<07:02,  2.82s/it]Training:  68%|██████▊   | 322/471 [13:26<06:11,  2.49s/it]Training:  69%|██████▉   | 325/471 [13:36<06:54,  2.84s/it]Training:  69%|██████▉   | 326/471 [13:36<05:59,  2.48s/it]Training:  70%|██████▉   | 329/471 [13:47<06:45,  2.85s/it]Training:  70%|███████   | 330/471 [13:47<05:49,  2.48s/it]Training:  71%|███████   | 333/471 [13:57<06:33,  2.85s/it]Training:  71%|███████   | 334/471 [13:58<05:43,  2.51s/it]Training:  72%|███████▏  | 337/471 [14:08<06:22,  2.86s/it]Training:  72%|███████▏  | 338/471 [14:09<05:38,  2.54s/it]Training:  72%|███████▏  | 341/471 [14:18<06:02,  2.79s/it]Training:  73%|███████▎  | 342/471 [14:20<05:24,  2.51s/it]Training:  73%|███████▎  | 345/471 [14:29<05:45,  2.74s/it]Training:  73%|███████▎  | 346/471 [14:30<05:11,  2.49s/it]Training:  74%|███████▍  | 349/471 [14:39<05:31,  2.72s/it]Training:  74%|███████▍  | 350/471 [14:40<04:55,  2.44s/it]Training:  75%|███████▍  | 353/471 [14:50<05:23,  2.74s/it]Training:  75%|███████▌  | 354/471 [14:51<04:46,  2.45s/it]Training:  76%|███████▌  | 357/471 [15:00<05:14,  2.76s/it]Training:  76%|███████▌  | 358/471 [15:01<04:39,  2.47s/it]Training:  77%|███████▋  | 361/471 [15:11<05:05,  2.77s/it]Training:  77%|███████▋  | 362/471 [15:12<04:31,  2.49s/it]Training:  77%|███████▋  | 365/471 [15:20<04:28,  2.53s/it]Training:  78%|███████▊  | 366/471 [15:20<03:54,  2.23s/it]Training:  78%|███████▊  | 369/471 [15:28<04:03,  2.38s/it]Training:  79%|███████▊  | 370/471 [15:29<03:30,  2.08s/it]Training:  79%|███████▉  | 373/471 [15:37<03:53,  2.38s/it]Training:  79%|███████▉  | 374/471 [15:38<03:24,  2.11s/it]Training:  80%|████████  | 377/471 [15:47<03:52,  2.48s/it]Training:  80%|████████  | 378/471 [15:47<03:21,  2.16s/it]Training:  81%|████████  | 381/471 [15:56<03:43,  2.49s/it]Training:  81%|████████  | 382/471 [15:57<03:14,  2.19s/it]Training:  82%|████████▏ | 385/471 [16:06<03:39,  2.55s/it]Training:  82%|████████▏ | 386/471 [16:07<03:13,  2.28s/it]Training:  83%|████████▎ | 389/471 [16:17<03:36,  2.64s/it]Training:  83%|████████▎ | 390/471 [16:17<03:09,  2.34s/it]Training:  83%|████████▎ | 393/471 [16:27<03:26,  2.64s/it]Training:  84%|████████▎ | 394/471 [16:27<02:59,  2.34s/it]Training:  84%|████████▍ | 397/471 [16:37<03:14,  2.63s/it]Training:  85%|████████▍ | 398/471 [16:37<02:47,  2.29s/it]Training:  85%|████████▌ | 401/471 [16:46<02:56,  2.53s/it]Training:  85%|████████▌ | 402/471 [16:47<02:35,  2.26s/it]Training:  86%|████████▌ | 405/471 [16:55<02:45,  2.51s/it]Training:  86%|████████▌ | 406/471 [16:56<02:24,  2.22s/it]Training:  87%|████████▋ | 409/471 [17:05<02:36,  2.52s/it]Training:  87%|████████▋ | 410/471 [17:05<02:14,  2.21s/it]Training:  88%|████████▊ | 413/471 [17:15<02:30,  2.60s/it]Training:  88%|████████▊ | 414/471 [17:15<02:08,  2.25s/it]Training:  89%|████████▊ | 417/471 [17:25<02:21,  2.62s/it]Training:  89%|████████▊ | 418/471 [17:25<02:02,  2.31s/it]Training:  89%|████████▉ | 421/471 [17:35<02:11,  2.62s/it]Training:  90%|████████▉ | 422/471 [17:36<01:55,  2.36s/it]Training:  90%|█████████ | 425/471 [17:45<02:00,  2.62s/it]Training:  90%|█████████ | 426/471 [17:46<01:46,  2.37s/it]Training:  91%|█████████ | 429/471 [17:55<01:51,  2.66s/it]Training:  91%|█████████▏| 430/471 [17:56<01:38,  2.40s/it]Training:  92%|█████████▏| 433/471 [18:06<01:44,  2.74s/it]Training:  92%|█████████▏| 434/471 [18:07<01:31,  2.47s/it]Training:  93%|█████████▎| 437/471 [18:16<01:34,  2.78s/it]Training:  93%|█████████▎| 438/471 [18:18<01:23,  2.53s/it]Training:  94%|█████████▎| 441/471 [18:27<01:21,  2.73s/it]Training:  94%|█████████▍| 442/471 [18:28<01:12,  2.49s/it]Training:  94%|█████████▍| 445/471 [18:38<01:12,  2.80s/it]Training:  95%|█████████▍| 446/471 [18:39<01:03,  2.54s/it]Training:  95%|█████████▌| 449/471 [18:48<01:00,  2.76s/it]Training:  96%|█████████▌| 450/471 [18:49<00:52,  2.48s/it]Training:  96%|█████████▌| 453/471 [18:58<00:48,  2.70s/it]Training:  96%|█████████▋| 454/471 [18:59<00:41,  2.44s/it]Training:  97%|█████████▋| 457/471 [19:09<00:37,  2.69s/it]Training:  97%|█████████▋| 458/471 [19:09<00:31,  2.40s/it]Training:  98%|█████████▊| 461/471 [19:19<00:27,  2.71s/it]Training:  98%|█████████▊| 462/471 [19:20<00:21,  2.44s/it]Training:  99%|█████████▊| 465/471 [19:29<00:16,  2.69s/it]Training:  99%|█████████▉| 466/471 [19:30<00:11,  2.39s/it]Training: 100%|█████████▉| 469/471 [19:37<00:04,  2.36s/it]Training: 100%|█████████▉| 470/471 [19:37<00:02,  2.07s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Training: 100%|██████████| 471/471 [19:38<00:00,  2.50s/it]
Evaluating:   0%|          | 0/118 [00:00<?, ?it/s]Evaluating:   1%|          | 1/118 [00:11<23:10, 11.89s/it]Evaluating:   4%|▍         | 5/118 [00:23<07:47,  4.14s/it]Evaluating:   6%|▌         | 7/118 [00:23<04:51,  2.63s/it]Evaluating:   8%|▊         | 9/118 [00:33<06:25,  3.53s/it]Evaluating:  11%|█         | 13/118 [00:44<05:23,  3.08s/it]Evaluating:  12%|█▏        | 14/118 [00:44<04:39,  2.69s/it]Evaluating:  14%|█▍        | 17/118 [00:54<04:55,  2.92s/it]Evaluating:  15%|█▌        | 18/118 [00:55<04:15,  2.55s/it]Evaluating:  18%|█▊        | 21/118 [01:05<04:39,  2.88s/it]Evaluating:  19%|█▊        | 22/118 [01:05<04:02,  2.53s/it]Evaluating:  21%|██        | 25/118 [01:16<04:28,  2.89s/it]Evaluating:  22%|██▏       | 26/118 [01:16<03:50,  2.51s/it]Evaluating:  25%|██▍       | 29/118 [01:26<04:08,  2.80s/it]Evaluating:  25%|██▌       | 30/118 [01:27<03:37,  2.47s/it]Evaluating:  26%|██▋       | 31/118 [01:27<03:00,  2.08s/it]Evaluating:  28%|██▊       | 33/118 [01:37<04:21,  3.07s/it]Evaluating:  29%|██▉       | 34/118 [01:38<03:45,  2.69s/it]Evaluating:  31%|███▏      | 37/118 [01:48<03:56,  2.92s/it]Evaluating:  32%|███▏      | 38/118 [01:49<03:30,  2.63s/it]Evaluating:  35%|███▍      | 41/118 [01:58<03:40,  2.87s/it]Evaluating:  36%|███▌      | 42/118 [02:00<03:14,  2.56s/it]Evaluating:  38%|███▊      | 45/118 [02:09<03:28,  2.85s/it]Evaluating:  39%|███▉      | 46/118 [02:10<02:58,  2.47s/it]Evaluating:  40%|███▉      | 47/118 [02:10<02:28,  2.09s/it]Evaluating:  42%|████▏     | 49/118 [02:20<03:33,  3.09s/it]Evaluating:  42%|████▏     | 50/118 [02:21<02:53,  2.54s/it]Evaluating:  43%|████▎     | 51/118 [02:21<02:20,  2.09s/it]Evaluating:  45%|████▍     | 53/118 [02:31<03:27,  3.19s/it]Evaluating:  46%|████▌     | 54/118 [02:31<02:44,  2.57s/it]Evaluating:  47%|████▋     | 55/118 [02:32<02:12,  2.10s/it]Evaluating:  47%|████▋     | 56/118 [02:32<01:39,  1.61s/it]Evaluating:  48%|████▊     | 57/118 [02:42<03:46,  3.71s/it]Evaluating:  49%|████▉     | 58/118 [02:42<02:55,  2.92s/it]Evaluating:  50%|█████     | 59/118 [02:43<02:07,  2.17s/it]Evaluating:  51%|█████     | 60/118 [02:43<01:37,  1.68s/it]Evaluating:  52%|█████▏    | 61/118 [02:52<03:40,  3.87s/it]Evaluating:  53%|█████▎    | 62/118 [02:54<02:56,  3.15s/it]Evaluating:  54%|█████▍    | 64/118 [02:54<01:39,  1.84s/it]Evaluating:  55%|█████▌    | 65/118 [03:03<03:12,  3.64s/it]Evaluating:  56%|█████▌    | 66/118 [03:05<02:37,  3.03s/it]Evaluating:  57%|█████▋    | 67/118 [03:05<01:55,  2.26s/it]Evaluating:  58%|█████▊    | 68/118 [03:06<01:30,  1.81s/it]Evaluating:  58%|█████▊    | 69/118 [03:14<03:00,  3.68s/it]Evaluating:  59%|█████▉    | 70/118 [03:15<02:23,  2.99s/it]Evaluating:  60%|██████    | 71/118 [03:16<01:45,  2.24s/it]Evaluating:  61%|██████    | 72/118 [03:16<01:18,  1.70s/it]Evaluating:  62%|██████▏   | 73/118 [03:25<02:46,  3.71s/it]Evaluating:  63%|██████▎   | 74/118 [03:26<02:07,  2.90s/it]Evaluating:  64%|██████▎   | 75/118 [03:26<01:39,  2.30s/it]Evaluating:  64%|██████▍   | 76/118 [03:27<01:10,  1.69s/it]Evaluating:  65%|██████▌   | 77/118 [03:35<02:33,  3.75s/it]Evaluating:  66%|██████▌   | 78/118 [03:36<01:53,  2.83s/it]Evaluating:  67%|██████▋   | 79/118 [03:37<01:28,  2.28s/it]Evaluating:  68%|██████▊   | 80/118 [03:37<01:02,  1.65s/it]Evaluating:  69%|██████▊   | 81/118 [03:46<02:18,  3.74s/it]Evaluating:  69%|██████▉   | 82/118 [03:46<01:40,  2.80s/it]Evaluating:  70%|███████   | 83/118 [03:47<01:19,  2.26s/it]Evaluating:  71%|███████   | 84/118 [03:48<00:55,  1.64s/it]Evaluating:  72%|███████▏  | 85/118 [03:56<02:06,  3.82s/it]Evaluating:  73%|███████▎  | 86/118 [03:57<01:31,  2.85s/it]Evaluating:  74%|███████▎  | 87/118 [03:58<01:11,  2.31s/it]Evaluating:  75%|███████▍  | 88/118 [03:58<00:49,  1.66s/it]Evaluating:  75%|███████▌  | 89/118 [04:07<01:46,  3.68s/it]Evaluating:  76%|███████▋  | 90/118 [04:07<01:19,  2.84s/it]Evaluating:  77%|███████▋  | 91/118 [04:09<01:02,  2.31s/it]Evaluating:  78%|███████▊  | 92/118 [04:09<00:44,  1.72s/it]Evaluating:  79%|███████▉  | 93/118 [04:15<01:16,  3.06s/it]Evaluating:  80%|███████▉  | 94/118 [04:16<00:56,  2.36s/it]Evaluating:  81%|████████  | 95/118 [04:16<00:41,  1.80s/it]Evaluating:  81%|████████▏ | 96/118 [04:17<00:31,  1.43s/it]Evaluating:  82%|████████▏ | 97/118 [04:22<00:56,  2.69s/it]Evaluating:  83%|████████▎ | 98/118 [04:23<00:42,  2.14s/it]Evaluating:  84%|████████▍ | 99/118 [04:24<00:31,  1.68s/it]Evaluating:  85%|████████▍ | 100/118 [04:25<00:25,  1.42s/it]Evaluating:  86%|████████▌ | 101/118 [04:30<00:44,  2.64s/it]Evaluating:  86%|████████▋ | 102/118 [04:31<00:34,  2.19s/it]Evaluating:  87%|████████▋ | 103/118 [04:32<00:26,  1.78s/it]Evaluating:  88%|████████▊ | 104/118 [04:33<00:21,  1.54s/it]Evaluating:  89%|████████▉ | 105/118 [04:39<00:36,  2.78s/it]Evaluating:  90%|████████▉ | 106/118 [04:40<00:28,  2.38s/it]Evaluating:  91%|█████████ | 107/118 [04:41<00:20,  1.90s/it]Evaluating:  92%|█████████▏| 108/118 [04:42<00:16,  1.65s/it]Evaluating:  92%|█████████▏| 109/118 [04:47<00:24,  2.74s/it]Evaluating:  93%|█████████▎| 110/118 [04:49<00:18,  2.33s/it]Evaluating:  94%|█████████▍| 111/118 [04:50<00:13,  1.93s/it]Evaluating:  95%|█████████▍| 112/118 [04:51<00:10,  1.71s/it]Evaluating:  96%|█████████▌| 113/118 [04:55<00:12,  2.52s/it]Evaluating:  97%|█████████▋| 114/118 [04:57<00:08,  2.19s/it]Evaluating:  97%|█████████▋| 115/118 [04:57<00:04,  1.64s/it]Evaluating:  98%|█████████▊| 116/118 [04:58<00:02,  1.43s/it]Evaluating:  99%|█████████▉| 117/118 [05:02<00:02,  2.20s/it]/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home2/s439765/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Evaluating: 100%|██████████| 118/118 [05:02<00:00,  2.57s/it]
/home2/s439765/.conda/envs/yolov8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
