{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pydicom\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# Set device for training\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device} device\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Weighted Logarithmic Loss\n",
    "class WeightedLogLoss(nn.Module):\n",
    "    def __init__(self, weights=None):\n",
    "        super().__init__()\n",
    "        self.epsilon = 1e-15\n",
    "        self.weights = torch.tensor(weights, dtype=torch.float32).to(device) if weights else None\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = torch.clamp(preds, min=self.epsilon, max=1 - self.epsilon)\n",
    "        log_loss = - (targets * torch.log(preds) + (1 - targets) * torch.log(1 - preds))\n",
    "        \n",
    "        if self.weights is not None:\n",
    "            log_loss *= self.weights\n",
    "        return log_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve Visualization\n",
    "def plot_roc_curves(y_true, y_pred, classes):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"ROC curve ({class_name})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model and Plot Confusion Matrix\n",
    "def evaluate_and_plot(model, data_loader, criterion, class_names):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = (np.array(y_pred) > 0.5).astype(int)\n",
    "\n",
    "    # Calculate Evaluation Metrics\n",
    "    accuracy = accuracy_score(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    sensitivity = recall_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "    specificity = precision_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n",
    "\n",
    "    print(f\"\\nValidation Loss: {val_loss / len(data_loader):.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names)\n",
    "    plot_roc_curves(y_true, y_pred, class_names)\n",
    "\n",
    "    return accuracy, sensitivity, specificity, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m class_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepidural\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintraparenchymal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintraventricular\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubarachnoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubdural\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate and plot confusion matrix\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m WeightedLogLoss(weights\u001b[38;5;241m=\u001b[39m\u001b[43mweights\u001b[49m)\n\u001b[1;32m      5\u001b[0m evaluate_and_plot(model, val_loader, criterion, class_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "class_names = [\"epidural\", \"intraparenchymal\", \"intraventricular\", \"subarachnoid\", \"subdural\", \"any\"]\n",
    "\n",
    "# Evaluate and plot confusion matrix\n",
    "criterion = WeightedLogLoss(weights=weights)\n",
    "evaluate_and_plot(model, val_loader, criterion, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Convert DICOM to PNG\n",
    "def convert_dicom_to_png_worker(args):\n",
    "    dicom_path, output_dir = args\n",
    "    try:\n",
    "        dcm = pydicom.read_file(dicom_path)\n",
    "        img = dcm.pixel_array.astype(np.float32)\n",
    "\n",
    "        # Normalize image to [0, 255]\n",
    "        img_min = img.min()\n",
    "        img_max = img.max()\n",
    "        img = ((img - img_min) / (img_max - img_min) * 255).astype(np.uint8)\n",
    "\n",
    "        # Save as PNG\n",
    "        img_id = os.path.basename(dicom_path).replace(\".dcm\", \".png\")\n",
    "        output_file = os.path.join(output_dir, img_id)\n",
    "        Image.fromarray(img).save(output_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dicom_path}: {e}\")\n",
    "\n",
    "\n",
    "# Batch Convert DICOM to PNG with Multi-Processing\n",
    "def batch_convert_to_png_mp(dicom_dir, output_dir, num_workers=72):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    dicom_files = [\n",
    "        os.path.join(dicom_dir, file)\n",
    "        for file in os.listdir(dicom_dir)\n",
    "        if file.endswith(\".dcm\")\n",
    "    ]\n",
    "\n",
    "    # Use all available CPUs if not specified\n",
    "    num_workers = num_workers or cpu_count()\n",
    "\n",
    "    print(f\"Starting Multi-Processing with {num_workers} workers...\")\n",
    "    with Pool(num_workers) as pool:\n",
    "        list(tqdm(pool.imap_unordered(\n",
    "            convert_dicom_to_png_worker, [(file, output_dir) for file in dicom_files]\n",
    "        ), total=len(dicom_files), desc=\"Converting DICOM to PNG\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess CSV Labels\n",
    "def preprocess(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df[['ImageID', 'Subtype']] = df['ID'].str.rsplit('_', n=1, expand=True)\n",
    "    df = df.groupby(['ImageID', 'Subtype'])['Label'].max().unstack(fill_value=0).reset_index()\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for PNG Images\n",
    "class PngDataset(Dataset):\n",
    "    def __init__(self, img_dir, df, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, f'{img_id}.png')\n",
    "\n",
    "        # Load PNG image\n",
    "        img = Image.open(img_path).convert('L')  # Grayscale\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.tensor(self.df.iloc[idx, 1:].values.astype('float32'))\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs=5):\n",
    "    best_roc_auc = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss, accuracy, sensitivity, specificity, roc_auc = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"\\nTrain Loss: {train_loss / len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if roc_auc > best_roc_auc:\n",
    "            print(f\"Saving Best Model with ROC AUC: {roc_auc:.4f}\")\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            best_roc_auc = roc_auc\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    sensitivity = recall_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "    specificity = precision_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n",
    "\n",
    "    return val_loss / len(data_loader), accuracy, sensitivity, specificity, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/s439765/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home2/s439765/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model Definition\n",
    "model = models.resnet34(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 6)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 3505/4706 [1:29:41<12:10,  1.64it/s]  "
     ]
    }
   ],
   "source": [
    "# Define Paths\n",
    "TRAIN_DICOM_DIR = './rsna-intracranial-hemorrhage-detection/stage_2_train'\n",
    "TRAIN_PNG_DIR = './rsna-intracranial-hemorrhage-detection/train_png'\n",
    "CSV_PATH = './rsna-intracranial-hemorrhage-detection/stage_2_train.csv'\n",
    "\n",
    "# Convert Images\n",
    "#batch_convert_to_png_mp(TRAIN_DICOM_DIR, TRAIN_PNG_DIR)\n",
    "\n",
    "# Preprocess CSV\n",
    "df = preprocess(CSV_PATH)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Data Loaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_dataset = PngDataset(TRAIN_PNG_DIR, train_df, transform=transform)\n",
    "val_dataset = PngDataset(TRAIN_PNG_DIR, val_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=16, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=128, shuffle=False, num_workers=16, pin_memory=True\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
