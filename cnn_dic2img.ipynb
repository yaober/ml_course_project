{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dicom_to_png_worker(args):\n",
    "    dicom_path, output_dir = args\n",
    "    try:\n",
    "        dcm = pydicom.read_file(dicom_path)\n",
    "        img = dcm.pixel_array.astype(np.float32)\n",
    "\n",
    "        # Normalize image to [0, 255]\n",
    "        img_min = img.min()\n",
    "        img_max = img.max()\n",
    "        img = ((img - img_min) / (img_max - img_min) * 255).astype(np.uint8)\n",
    "\n",
    "        # Save as PNG\n",
    "        img_id = os.path.basename(dicom_path).replace(\".dcm\", \".png\")\n",
    "        output_file = os.path.join(output_dir, img_id)\n",
    "        Image.fromarray(img).save(output_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dicom_path}: {e}\")\n",
    "\n",
    "\n",
    "# Batch Convert DICOM to PNG with Multi-Processing\n",
    "def batch_convert_to_png_mp(dicom_dir, output_dir, num_workers=72):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    dicom_files = [\n",
    "        os.path.join(dicom_dir, file)\n",
    "        for file in os.listdir(dicom_dir)\n",
    "        if file.endswith(\".dcm\")\n",
    "    ]\n",
    "\n",
    "    # Use all available CPUs if not specified\n",
    "    num_workers = num_workers or cpu_count()\n",
    "\n",
    "    print(f\"Starting Multi-Processing with {num_workers} workers...\")\n",
    "    with Pool(num_workers) as pool:\n",
    "        list(tqdm(pool.imap_unordered(\n",
    "            convert_dicom_to_png_worker, [(file, output_dir) for file in dicom_files]\n",
    "        ), total=len(dicom_files), desc=\"Converting DICOM to PNG\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess CSV Labels\n",
    "def preprocess(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df[['ImageID', 'Subtype']] = df['ID'].str.rsplit('_', n=1, expand=True)\n",
    "    df = df.groupby(['ImageID', 'Subtype'])['Label'].max().unstack(fill_value=0).reset_index()\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for PNG Images\n",
    "class PngDataset(Dataset):\n",
    "    def __init__(self, img_dir, df, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, f'{img_id}.png')\n",
    "\n",
    "        # Load PNG image\n",
    "        img = Image.open(img_path).convert('L')  # Grayscale\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.tensor(self.df.iloc[idx, 1:].values.astype('float32'))\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs=5):\n",
    "    best_roc_auc = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss, accuracy, sensitivity, specificity, roc_auc = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"\\nTrain Loss: {train_loss / len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if roc_auc > best_roc_auc:\n",
    "            print(f\"Saving Best Model with ROC AUC: {roc_auc:.4f}\")\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            best_roc_auc = roc_auc\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    sensitivity = recall_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "    specificity = precision_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n",
    "\n",
    "    return val_loss / len(data_loader), accuracy, sensitivity, specificity, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/s439765/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home2/s439765/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model Definition\n",
    "model = models.resnet34(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 6)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 3505/4706 [1:29:41<12:10,  1.64it/s]  "
     ]
    }
   ],
   "source": [
    "TRAIN_DICOM_DIR = './rsna-intracranial-hemorrhage-detection/stage_2_train'\n",
    "TRAIN_PNG_DIR = './rsna-intracranial-hemorrhage-detection/train_png'\n",
    "CSV_PATH = './rsna-intracranial-hemorrhage-detection/stage_2_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess CSV\n",
    "df = preprocess(CSV_PATH)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Data Loaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PngDataset(TRAIN_PNG_DIR, train_df, transform=transform)\n",
    "val_dataset = PngDataset(TRAIN_PNG_DIR, val_df, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=16, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=128, shuffle=False, num_workers=16, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
